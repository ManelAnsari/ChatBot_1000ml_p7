{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "_q5ud27D_tsj"
   },
   "source": [
    "## Import Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1403,
     "status": "ok",
     "timestamp": 1593191249598,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "VGM8okAl_2j7",
    "outputId": "711aca9f-2cb5-4158-cf9b-fe050024cd66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# We'll first need the data from my drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jxyi6xg_27d"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85618,
     "status": "ok",
     "timestamp": 1593191161656,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "3Bs3m5UP__hD",
    "outputId": "aaabecc0-a671-4e49-96b0-8d31f0882c0e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 71kB 2.0MB/s \n",
      "\u001b[K     |████████████████████████████████| 30.9MB 125kB/s \n",
      "\u001b[K     |████████████████████████████████| 204kB 47.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 5.7MB 43.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 235kB 47.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 266kB 48.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 92kB 10.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 2.1MB 42.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.2MB 45.5MB/s \n",
      "\u001b[?25h  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: fbprophet 0.6 has requirement python-dateutil>=2.8.0, but you'll have python-dateutil 2.7.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 276kB 8.4MB/s \n",
      "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: chatterbot 1.0.5 has requirement pyyaml<5.2,>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
      "\u001b[K     |████████████████████████████████| 11.1MB 2.7MB/s \n",
      "\u001b[?25h  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "Collecting colab-env\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/66/1845bc28d685894e6e203cfb2bdd9d19c86926d7a6f765e9497e218ab304/colab-env-0.2.0.tar.gz\n",
      "Collecting python-dotenv<1.0,>=0.10.0\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/2a/07f87440444fdf2c5870a710b6770d766a1c7df9c827b0c90e807f1fb4c5/python_dotenv-0.13.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: colab-env\n",
      "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for colab-env: filename=colab_env-0.2.0-cp36-none-any.whl size=3838 sha256=a249d68c305c8966871f7dd3bc89f8578f968489273990225dbf2c907d14b63f\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/9c/85/7ec1faca43d1a5df32f33f4e22d5ae91f301a5406779528ead\n",
      "Successfully built colab-env\n",
      "Installing collected packages: python-dotenv, colab-env\n",
      "Successfully installed colab-env-0.2.0 python-dotenv-0.13.0\n",
      "Collecting amadeus\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/32/a07017dd416e829ddff277c3311868427f0c84aedbf8e0d420b0005fd26f/amadeus-4.1.0-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
      "\u001b[?25hInstalling collected packages: amadeus\n",
      "Successfully installed amadeus-4.1.0\n"
     ]
    }
   ],
   "source": [
    "# Need both chatterbot and chatterbot-corpus\n",
    "!pip install chatterbot -qq\n",
    "!pip install chatterbot-corpus -qq\n",
    "# The above libraries compatible with earlier SpaCy. Need to download from what they ^ install.\n",
    "!python -m spacy download en_core_web_sm -qq\n",
    "# Using env variables, need this library\n",
    "!pip install colab-env --upgrade\n",
    "# For the API\n",
    "!pip install amadeus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1593191254830,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "jbI3Em2cAL3b",
    "outputId": "193d3175-6da8-41e5-8e8c-a663d6ec4af0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/karl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/karl/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/karl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "path='data/'\n",
    "#import colab_env\n",
    "import os\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='')\n",
    "# The API\n",
    "from amadeus import Client, ResponseError\n",
    "\n",
    "# This library can extract dates from text\n",
    "import dateutil.parser as dparser\n",
    "\n",
    "# We'll need the following nltk packages\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# We'll use lemmas instead of stems.\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# We will tag the parts of the speech \n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Get the stop words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# We'll need json to open a file of intents\n",
    "import json\n",
    "\n",
    "# We will need to save the model\n",
    "import pickle\n",
    "\n",
    "# Some helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "# We'll need these to actually create a machine learning model.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, Adagrad, Adam, Adadelta\n",
    "\n",
    "# We may need to try out a grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We'll need this for the in-code tagging of words\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRlzmF2WBO5y"
   },
   "source": [
    "## Greetings and Farewells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1593191186851,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "9jhLmuzyBTts"
   },
   "outputs": [],
   "source": [
    "# Greetings\n",
    "hellos = [['Hello!','Hi there'],\n",
    "          ['Hi there','Hello!'],\n",
    "          ['Greetings','Hey'],\n",
    "          ['Hey','Oh hey!'],\n",
    "          ['Good morning','Good morning'],\n",
    "          ['Good evening','Good evening'],\n",
    "          ['Hey there!','Well hello there']\n",
    "         ]\n",
    "\n",
    "# Farewells\n",
    "byes = [['Bye','Goodbye!'],\n",
    "        ['See ya','Good bye!'],\n",
    "        ['Have a good night','You as well, goodbye!'],\n",
    "        ['Farewell','Later!'],\n",
    "        ['Goodbye!', 'Bye for now!']\n",
    "       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfGOZ8fwCARg"
   },
   "source": [
    "## Basic Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1593191188266,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "MuABqCu7CEMD"
   },
   "outputs": [],
   "source": [
    "convo1=[\"I would like to book a flight.\",\n",
    "        \"I can help you with that. Where are you traveling to?\",\n",
    "        \"I am traveling to Singapore.\",\n",
    "        \"What date will you be traveling?\",\n",
    "        \"I want to fly on June 14th.\",\n",
    "        \"When would you like to return?\"]\n",
    "\n",
    "convo2=['I want to buy a plane ticket.',\n",
    "        'I can help you make your reservation. What is your destination?',\n",
    "        'My final destination is Sydney, Australia.',\n",
    "        'What is your travel date?',\n",
    "        'I am making a reservation for December 12th.',\n",
    "        'Fantastic, when will you need to come back?']\n",
    "\n",
    "convo3=['I need to make a plane reservation.',\n",
    "        'We can book your trip right now. What city are you flying to?',\n",
    "        'I need to fly to New York City.',\n",
    "        'What date would you like me to book this plane ticket(s) for?',\n",
    "        'I need a flight on July 4th.',\n",
    "        \"Awesome, when do you think you'd like to return?\"]\n",
    "\n",
    "convo4=['I want to take a vacation',\n",
    "        'We can help you with that! What were you thinking?',\n",
    "        'I was thinking Dominica.',\n",
    "        'When would you like to leave?',\n",
    "        'I need a flight on March 3rd.',\n",
    "        \"Let's get booking then! I'll need your return date.\"]\n",
    "convo5=['I need a goddamn vacation',\n",
    "        'Where do you come from, where do you go? Where are you coming from, Cotton Eyed Joe?',\n",
    "        \"That was random, but I think I'll check out London\",\n",
    "        \"Radical, let's get to booking! When did you want to leave?\",\n",
    "        \"Probably this week, June 29th, 2020\",\n",
    "        \"Excellent, I only have a few more questions for you.\"\n",
    "        ]\n",
    "\n",
    "convos = [convo1,convo2,convo3, convo4, convo5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUbrUcDQDk4Y"
   },
   "source": [
    "## Training the Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2M_15dRDtoa"
   },
   "source": [
    "For this, we'll actually also import the english corpus for a little more flexibility in what the chatbot can say. That way it can hold a brief conversation before booking the flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1593191195434,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "UPnnvwxlDsaz",
    "outputId": "d7bde75c-c77b-4308-f72a-d44627741160"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/karl/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/karl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/karl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# We will first train the bot with the lists of data we've given it above.\n",
    "chatbot = ChatBot('Traveller',logic_adapters=[\"chatterbot.logic.BestMatch\"])\n",
    "travel_listtrainer = ListTrainer(chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3110,
     "status": "ok",
     "timestamp": 1593191198730,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "FnYZ4bPIECBL",
    "outputId": "b3c0792f-614b-4824-c66c-99d34318d22e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n",
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "for convo in convos:\n",
    "  travel_listtrainer.train(convo)\n",
    "\n",
    "for hi in hellos:\n",
    "  travel_listtrainer.train(hi)\n",
    "\n",
    "for bye in byes:\n",
    "  travel_listtrainer.train(bye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1724,
     "status": "ok",
     "timestamp": 1593191198735,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "va5JlghUEKbL"
   },
   "outputs": [],
   "source": [
    "# Next we will need to train in with the corpus.\n",
    "travel_corpustrainer = ChatterBotCorpusTrainer(chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5292,
     "status": "ok",
     "timestamp": 1593191203401,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "SrfXT0uBEZMr",
    "outputId": "952c0651-bac4-4992-f41f-636bf4759643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Training ai.yml: [                    ] 1%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karl/Documents/chatbot/ChatBot_1000ml_p7/cb_env/lib/python3.8/site-packages/chatterbot/corpus.py:38: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return yaml.load(data_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [####################] 100%\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "travel_corpustrainer.train(\"chatterbot.corpus.english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to make functions more streamlined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I want to do here is to make it so that everytime a user inputs a message, the chatbot looks for the entities that it needs. So we will start with the looker function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_looker(message):\n",
    "    '''\n",
    "    This function looks at a message from the user and seeks for matches in dates, locations and budget\n",
    "    and outputs a value of True if they are contained in the message. \n",
    "    '''\n",
    "    \n",
    "    # Tokenize the sentence for entity matching.\n",
    "    tokens = nlp(message)\n",
    "    \n",
    "    date_from_matcher = Matcher(nlp.vocab)\n",
    "    date_from_matcher.add(\"DateFromFinder\", None, [{'LOWER':'leave'}, {'LOWER':'on'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                                  [{'LOWER':'leaving'}, {'LOWER':'on'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                                  [{'LOWER':'leave'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                                  [{'LOWER':'leaving'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                                  [{'LOWER':'go'}, {'LOWER':'on'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                                  [{'LOWER':'on'}, {\"ENT_TYPE\": \"DATE\"}], \n",
    "                                                  [{'LOWER':'from'}, {\"ENT_TYPE\": \"DATE\"}])\n",
    "    \n",
    "    date_to_matcher = Matcher(nlp.vocab)\n",
    "    date_to_matcher.add(\"DateToFinder\", None, [{'LOWER':'return'},{'LOWER':'on'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                              [{'LOWER':'returning'},{'LOWER':'on'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                              [{'LOWER':'return'},{\"ENT_TYPE\": \"DATE\"}],\n",
    "                                              [{'LOWER':'returning'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                              [{'LOWER':'back'},{'LOWER':'on'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                              [{'LOWER':'to'}, {\"ENT_TYPE\": \"DATE\"}])\n",
    "    \n",
    "    origin_matcher = Matcher(nlp.vocab)\n",
    "    origin_matcher.add(\"OriginFinder\", None, [{'LOWER':'from'},{'ENT_TYPE':'GPE'}],\n",
    "                                             [{'LOWER':'of'},{'ENT_TYPE':'GPE'}],\n",
    "                                             [{'LOWER':'leaving'},{'ENT_TYPE':'GPE'}],\n",
    "                                             [{'LOWER':'leave'},{'ENT_TYPE':'GPE'}])\n",
    "    dest_matcher = Matcher(nlp.vocab)\n",
    "    dest_matcher.add(\"DestinationFinder\", None, [{'LOWER':'to'},{'ENT_TYPE':'GPE'}],\n",
    "                                                [{'LOWER':'visit'},{'ENT_TYPE':'GPE'}],\n",
    "                                                [{'LOWER':'see'},{'ENT_TYPE':'GPE'}],\n",
    "                                                [{'LOWER':'out'},{'ENT_TYPE':'GPE'}],\n",
    "                                                [{'LOWER':'travel'},{'ENT_TYPE':'GPE'}])\n",
    "    \n",
    "    budget_matcher = Matcher(nlp.vocab)\n",
    "    budget_matcher.add('BudgetFinder', None, [{'LOWER':'of'},{'IS_DIGIT':True}],\n",
    "                                             [{'LOWER':'spend'},{'IS_DIGIT':True}],\n",
    "                                             [{'LOWER':'under'},{'IS_DIGIT':True}],\n",
    "                                             [{'LOWER':'than'},{'IS_DIGIT':True}],\n",
    "                                             [{'ENT_TYPE':'MONEY'}],\n",
    "                                             [{'ORTH':'$'},{'IS_DIGIT':True}])\n",
    "    \n",
    "    # This portion uses the boolean nature of an empty list. If the list is empty, we get False, else True\n",
    "    # Date From Match\n",
    "    DF_match = not not date_from_matcher(tokens)\n",
    "    \n",
    "    # Date To Match\n",
    "    DT_match = not not date_to_matcher(tokens)\n",
    "    \n",
    "    # Origin Match\n",
    "    O_match = not not origin_matcher(tokens)\n",
    "    \n",
    "    # Destination Match\n",
    "    D_match = not not dest_matcher(tokens)\n",
    "    \n",
    "    # Budget Match\n",
    "    B_match = not not budget_matcher(tokens)\n",
    "    \n",
    "    # This returns a tuple of the Trues/Falses, so the functions know what they are looking for specifically.\n",
    "    return (DF_match, DT_match, O_match, D_match, B_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_picker(message):\n",
    "    '''\n",
    "    This function takes the match information, and calls on the functions necessary to extract the info\n",
    "    from the message. It then converts the entities that it picked out to an API readable form.\n",
    "    It then returns a set of the entities. If there were no matches, it returns None.\n",
    "    '''\n",
    "    \n",
    "    matches = entity_looker(message)\n",
    "    from_date = to_date = origin_code = dest_code = budget_int = None\n",
    "    \n",
    "    # From Date match\n",
    "    if matches[0]:\n",
    "        # Get the from date (comes back as DateTime)\n",
    "        from_date_dt = get_from_dates(message)\n",
    "        # Convert dates for API\n",
    "        from_date = convert_date(from_date_dt)\n",
    "    \n",
    "    # To Date match\n",
    "    if matches[1]:\n",
    "        # Get the from date (comes back as DateTime)\n",
    "        to_date_dt = get_to_dates(message)\n",
    "        # Convert dates for API\n",
    "        to_date = convert_date(to_date_dt)\n",
    "        \n",
    "    # Origin Location match\n",
    "    if matches[2]:\n",
    "        # Get the origin location\n",
    "        origin = get_origin(message)\n",
    "        # convert to IATA code\n",
    "        origin_code = iata_code(origin)\n",
    "    \n",
    "    # Destination Location match\n",
    "    if matches[3]:\n",
    "        # get the destination location\n",
    "        dest = get_dest(message)\n",
    "        # convert to IATA code\n",
    "        dest_code = iata_code(dest)\n",
    "    \n",
    "    # Budget match\n",
    "    if matches[4]:\n",
    "        # get the budget\n",
    "        budget = get_budget(message)\n",
    "        # convert to int\n",
    "        budget_int = int(budget)\n",
    "    \n",
    "    return (from_date, to_date, origin_code, dest_code, budget_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Date Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_dates(message):\n",
    "    '''\n",
    "    This function is designed to extract a datetime object from the \"from date\". Here it is also necessary to \n",
    "    distinguish between the from/to dates if they are both included in a single message. Thankfully, SpaCy lists\n",
    "    them in order of appearance. \n",
    "    It will be an important note that for the purposes of this project, I will _assume_ that (if there are two\n",
    "    dates present) the date which  appears first is the from date, and the second is the to date. There is no \n",
    "    good reason that proper English would lead someone to list both dates in the reverse order.\n",
    "    This function assumes that there is at least one date present in the message.\n",
    "    '''\n",
    "    import datetime\n",
    "    # Tokenize\n",
    "    tokens = nlp(message)\n",
    "    # Extract entities\n",
    "    entities = [(X.label_, X.text) for X in tokens.ents]\n",
    "    # get rid of anything not a date\n",
    "    dates = [x for x in entities if x[0]=='DATE']\n",
    "    \n",
    "    # Next, we will look to see if someone used the words \"tomorrow\", \"next week\" or \"today\"\n",
    "    text = [x[1] for x in dates]\n",
    "    today = datetime.datetime.today()\n",
    "    if 'today' in text:\n",
    "        from_date = today\n",
    "    elif 'tomorrow' in text:\n",
    "        from_date = today + datetime.timedelta(days=1)\n",
    "    elif 'next week' in text:\n",
    "        from_date = today + datetime.timedelta(days=7)\n",
    "    else:\n",
    "        if len(dates)>1:\n",
    "            try: \n",
    "                from_date = dparser.parse(dates[0][1],fuzzy=True)\n",
    "                to_date = dparser.parse(dates[1][1], fuzzy=True)\n",
    "            except:\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'on Friday July 10th 2020 I want to leave on a vacation to toronto'\n",
    "string2 = 'next week, I want to leave on a vacation to toronto tomorrow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DATE', 'next week'), ('GPE', 'toronto'), ('DATE', 'tomorrow')]\n",
      "[('DATE', 'next week'), ('DATE', 'tomorrow')]\n"
     ]
    }
   ],
   "source": [
    "get_from_dates(string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 7, 8, 15, 23, 43, 387061)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSWb5SvtH2m6"
   },
   "source": [
    "## Get the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1593191211040,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "d9vCDoKuH0tp"
   },
   "outputs": [],
   "source": [
    "# We'll note here that I'll have to consider what happens when the bot asks for the second date. Does it run through this again, or do I create a second function. \n",
    "# This will have to be changed depending on the global variables I choose to inlcude\n",
    "\n",
    "def get_dates(message):\n",
    "    '''\n",
    "    This function checks if there are any dates in the message, if so it pulls them out. If there are two dates, then we need to\n",
    "    parse the list more closely to pull out each date. This function assumes that the date(s) was/were written in a readable form.\n",
    "    '''\n",
    "    # Remove punctuation\n",
    "    clean_message = re.sub(r'[^\\w\\s]','',message)\n",
    "    # The first try checks if there are some dates. If there are none or two, it throws a ValueError\n",
    "    # The second try assumes that there were actually two dates, if this is not true, then it returns nothing.\n",
    "    try:\n",
    "        depart_date = dparser.parse(clean_message,fuzzy=True)\n",
    "        return_date = None\n",
    "        data_flag = True\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # I will also assume here that the second date given is the return date\n",
    "            # As a final assumption, we assume that there are only two dates given maximum.\n",
    "            # Let's first recognize the positions of the dates in the string.\n",
    "            matcher = Matcher(nlp.vocab)\n",
    "            matcher.add(\"DateFinder\", None, [{'LOWER':'on'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                          [{'LOWER':'from'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                          [{'LOWER':'to'}, {\"ENT_TYPE\": \"DATE\"}],\n",
    "                                          [{'IS_STOP':True}, {\"ENT_TYPE\": \"DATE\"}])\n",
    "            matches = matcher(nlp(clean_message))\n",
    "            # First and second date index matchings\n",
    "            d1 = matches[0]\n",
    "            d2 = matches[1]\n",
    "            # Go from first part of date, to one word after (This gets the year, unless there is none, in which case it gets a filler word)\n",
    "            first_date = nlp(message)[d1[1]:d1[2]+2]\n",
    "            # If the message ends with the second date, then we need to be careful to not pick up an error\n",
    "            if (d2[2]==len(clean_message) or d2[2]+1==len(clean_message) or d2[2]+2==len(clean_message)):\n",
    "                second_date = nlp(clean_message)[d2[1]:]\n",
    "            else:\n",
    "                second_date = nlp(clean_message)[d2[1]:d2[2]+2]\n",
    "            depart_date = dparser.parse(str(first_date),fuzzy=True)\n",
    "            return_date = dparser.parse(str(second_date),fuzzy=True)\n",
    "            data_flag=True\n",
    "        except: \n",
    "            return_date = None\n",
    "            depart_date = None\n",
    "            data_flag = False\n",
    "\n",
    "    dates = (depart_date, return_date, data_flag)\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YonxjEYjSAyA"
   },
   "source": [
    "## Get the locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1593191212470,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "qeHQ7QVHSC51"
   },
   "outputs": [],
   "source": [
    "def get_locs(message):\n",
    "  # Remove punctuation\n",
    "  clean_message = re.sub(r'[^\\w\\s]','',message)\n",
    "\n",
    "  from_matcher = Matcher(nlp.vocab)\n",
    "  from_matcher.add(\"LocFinder\", None, [{'LOWER':'from'},{'ENT_TYPE':'GPE'}],\n",
    "                                      [{'LOWER':'of'},{'ENT_TYPE':'GPE'}])\n",
    "  to_matcher = Matcher(nlp.vocab)\n",
    "  to_matcher.add(\"LocFinder\", None, [{'LOWER':'to'},{'ENT_TYPE':'GPE'}],\n",
    "                                    [{'LOWER':'visit'},{'ENT_TYPE':'GPE'}],\n",
    "                                    [{'LOWER':'see'},{'ENT_TYPE':'GPE'}],\n",
    "                                    [{'LOWER':'out'},{'ENT_TYPE':'GPE'}],\n",
    "                                    [{'LOWER':'travel'},{'ENT_TYPE':'GPE'}])\n",
    "  from_match = from_matcher(nlp(clean_message))\n",
    "  to_match = to_matcher(nlp(clean_message))\n",
    "\n",
    "  if len(from_match)>0:\n",
    "    loc1 = from_match[0]\n",
    "    origin = str(nlp(clean_message)[loc1[1]+1])\n",
    "  else:\n",
    "    origin = None\n",
    "  if len(to_match)>0:\n",
    "    loc2 = to_match[0]\n",
    "    dest = str(nlp(clean_message)[loc2[1]+1])\n",
    "  else:\n",
    "    dest = None\n",
    "  \n",
    "  if (origin == None and dest == None):\n",
    "    data_flag = False\n",
    "  else:\n",
    "    data_flag = True\n",
    "  locations = (str(origin), str(dest), data_flag)\n",
    "\n",
    "  return locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFIrbmjm0U7W"
   },
   "source": [
    "## Get the budget!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1593191213944,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "ax8hK7RG0UiX"
   },
   "outputs": [],
   "source": [
    "def get_budget(message):\n",
    "  budget_matcher = Matcher(nlp.vocab)\n",
    "  budget_matcher.add('BudgetFinder', None, [{'LOWER':'of'},{'IS_DIGIT':True}],\n",
    "                                          [{'LOWER':'spend'},{'IS_DIGIT':True}],\n",
    "                                          [{'LOWER':'under'},{'IS_DIGIT':True}],\n",
    "                                          [{'LOWER':'than'},{'IS_DIGIT':True}],\n",
    "                                          [{'ENT_TYPE':'MONEY'}],\n",
    "                                          [{'ORTH':'$'},{'IS_DIGIT':True}])\n",
    "  match = budget_matcher(nlp(message))\n",
    "  try:\n",
    "    budget = nlp(message)[match[0][2]-1]\n",
    "  except IndexError:\n",
    "    budget = None\n",
    "\n",
    "  if budget == None:\n",
    "    data_flag=False\n",
    "  else:\n",
    "    data_flag = True\n",
    "  return (str(budget), data_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCeF9-zdfcXh"
   },
   "source": [
    "##  IATA Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1740,
     "status": "ok",
     "timestamp": 1593191262855,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "w4wA0vFpfblb"
   },
   "outputs": [],
   "source": [
    "city_code = pd.read_csv(f'Airports.csv').groupby('Location').max()\n",
    "code_dict = city_code.to_dict()['Code']\n",
    "def iata_code_lookup(city, codes, origin_city=True):\n",
    "  '''\n",
    "  This function takes in a city name as well as a dictionary with city names and their IATA codes. It then checks whether this is the origin city or not.\n",
    "  If the city is in the dictionary, it will output the code. Otherwise, it will output an empty string and an error message that depends on whether or not the city was the origin or destination.\n",
    "  '''\n",
    "  try: \n",
    "    iata_code = codes[city]\n",
    "  except KeyError:\n",
    "    iata_code = ''\n",
    "    if origin_city:\n",
    "      print(f'Unfortunately there are no flights leaving {city} at this time.')\n",
    "      return None\n",
    "    else:\n",
    "      print(f'Unfortunately there are no flights to {city} at this time.')\n",
    "      return None\n",
    "  return iata_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AqsqsRyyfssf"
   },
   "source": [
    "## The API stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1593191267602,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "2W_KNG84fuux"
   },
   "outputs": [],
   "source": [
    "def get_flight(flight_info, codes):\n",
    "  amadeus = Client(\n",
    "      client_id=os.getenv(\"AMADEUS_API_KEY\"),\n",
    "      client_secret=os.getenv(\"AMADEUS_SECRET\")\n",
    "  )\n",
    "\n",
    "  try:\n",
    "      response = amadeus.shopping.flight_offers_search.get(\n",
    "          originLocationCode = iata_code_lookup(flight_info['origin_loc'], codes, origin_city=True),\n",
    "          destinationLocationCode = iata_code_lookup(flight_info['dest_loc'], codes, origin_city=False),\n",
    "          departureDate=f\"{flight_info['depart_date'].year}-{str(flight_info['depart_date'].month) if int(flight_info['depart_date'].month)>9 else '0'+str(flight_info['depart_date'].month)}-{str(flight_info['depart_date'].day) if int(flight_info['depart_date'].day)>9 else '0'+str(flight_info['depart_date'].day)}\",\n",
    "          returnDate=f\"{flight_info['return_date'].year}-{str(flight_info['return_date'].month) if int(flight_info['return_date'].month)>9 else '0'+str(flight_info['return_date'].month)}-{str(flight_info['return_date'].day) if int(flight_info['return_date'].day)>9 else '0'+str(flight_info['return_date'].day)}\",\n",
    "          maxPrice=int(flight_info['budget']),\n",
    "          currencyCode='CAD',\n",
    "          adults=1)\n",
    "      print(f\"Your flight has been booked! Here are the details, tickets will be sent to you by email.\")\n",
    "      print(f\"Departure Time: {response.data[0]['itineraries'][0]['segments'][0]['departure']['at']}\") \n",
    "      print(f\"Arrival Time: {response.data[0]['itineraries'][0]['segments'][0]['arrival']['at']}\")\n",
    "      print(f\"Total Price: {response.data[0]['price']['total']}\")\n",
    "      print(f\"Flight Class: {response.data[0]['travelerPricings'][0]['fareDetailsBySegment'][0]['cabin']}\")\n",
    "  except ResponseError as error:\n",
    "      print(error)\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pO9SyrihR9io"
   },
   "source": [
    "## Run the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1593191270149,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "I9bz7hVYEmfq"
   },
   "outputs": [],
   "source": [
    "# Now that the chatterbot is trained reasonably, let's create the structure that loops through the conversation, until it has enough information to book a flight.\n",
    "def Traveler():\n",
    "  '''\n",
    "  Due to time constraints, I'm going to let the chatbot do its chatbot thing until it recognizes that a flight is being booked. At that point I'll kick in the script and argue that this is what a \n",
    "  human salesman would do...\n",
    "  '''\n",
    "  # this list of text queues the chatbot to quit\n",
    "  byes = ['Goodbye', 'Good bye','You as well, goodbye','Later', 'Bye for now','Bye','See ya','Have a good night','Farewell','Goodbye!', 'bye']\n",
    "  # First, we'll instantiate a dictionary for the values we want to populate.\n",
    "  flight_info = {'depart_date':0,\n",
    "                 'return_date':0,\n",
    "                 'origin_loc':0,\n",
    "                 'dest_loc':0,\n",
    "                 'budget':0\n",
    "                 }\n",
    "  conversation_ongoing = True\n",
    "\n",
    "  while conversation_ongoing:\n",
    "    user_input = input()\n",
    "    # If user says something that queues a goodbye message from the chatbot, it gets the chance to say that, and then the loop ends.\n",
    "    if any(bye in user_input for bye in byes):\n",
    "      print(random.choice(byes))\n",
    "      conversation_ongoing = False\n",
    "      break\n",
    "    # If there is no information in the travel dictionary, then the chatbot should hold the conversation\n",
    "    if not ((get_locs(user_input)[2]) or (get_dates(user_input)[2]) or (get_budget(user_input)[1])):\n",
    "      # Get chatbot response\n",
    "      print(chatbot.get_response(user_input))\n",
    "      \n",
    "    else:\n",
    "      # Get Locations, if any\n",
    "      if ((flight_info['dest_loc']==0) and (get_locs(user_input)==None)):\n",
    "        response_list_dest_loc = ['Where did you want to go?', 'Where were you thinking of travelling to?', 'Where to?']\n",
    "        print(random.choice(response_list_dest_loc))\n",
    "        user_input = input()\n",
    "        locations = get_locs(user_input)\n",
    "        flight_info['dest_loc']=locations[1]\n",
    "      else:\n",
    "        flight_info['dest_loc']=get_locs(user_input)[1]\n",
    "\n",
    "      if flight_info['origin_loc']==0:\n",
    "        response_list_origin_loc = ['Where are you leaving from?', 'What city are you flying out of?', 'Where ya coming from?']\n",
    "        print(random.choice(response_list_origin_loc))\n",
    "        user_input = input()\n",
    "        locations = get_locs(user_input)\n",
    "        flight_info['origin_loc']=locations[0]\n",
    "\n",
    "      # Get Dates, if any\n",
    "      if flight_info['depart_date']==0:\n",
    "        response_list_depart_date = ['When did you want to leave?', 'What dates were you thinking?', 'When is your travel date?', 'For what days should I book the flight?']\n",
    "        print(random.choice(response_list_depart_date))\n",
    "        user_input=input()\n",
    "        dates = get_dates(user_input)\n",
    "        flight_info['depart_date']=dates[0]\n",
    "\n",
    "      if flight_info['return_date']==0:\n",
    "        response_list_return_date = ['When did you want to come back?', 'When do you need to return?', 'What should I set for return date?']\n",
    "        print(random.choice(response_list_return_date))\n",
    "        user_input=input()\n",
    "        dates = get_dates(user_input)\n",
    "        flight_info['return_date']=dates[0]\n",
    "\n",
    "      # Get budget if any\n",
    "      if flight_info['budget']==0:\n",
    "        response_list_budget = ['How much are you willing to spend on this trip?', \"What's your budget for this trip?\", \"Do you have a price limit for the trip?\"]\n",
    "        print(random.choice(response_list_budget))\n",
    "        user_input = input()\n",
    "        budget = get_budget(user_input)\n",
    "        flight_info['budget'] = budget[0]\n",
    "      \n",
    "      if all(flight_info[key] != None for key in flight_info.keys()):\n",
    "        print(f\"So to recap, you want to book a trip from {flight_info['origin_loc']} to {flight_info['dest_loc']} for {flight_info['depart_date']} to {flight_info['return_date']} and you have a budget of {flight_info['budget']}. If this is correct, please say yes, if not, say no\")\n",
    "        user_input = input()\n",
    "        if (user_input.lower() in ['y', 'yes','yeah', 'yep']):\n",
    "          print(\"Excellent, let's, see what the system says. Loading...\")\n",
    "          get_flight(flight_info, code_dict)\n",
    "        else:\n",
    "          print(\"Oh, well thats too bad. Better luck next time!\")\n",
    "          break\n",
    "\n",
    "      # get number of people, maybe later\n",
    "\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jr-8uCCOmhzC"
   },
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 148239,
     "status": "ok",
     "timestamp": 1593125499712,
     "user": {
      "displayName": "Karl Davidson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64",
      "userId": "10038756410563164123"
     },
     "user_tz": 240
    },
    "id": "gdgBsTuBJfic",
    "outputId": "78afb55d-dce8-4580-dbc9-cd3664c64870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "Oh hey!\n",
      "hows it going\n",
      "Good\n",
      "how are you\n",
      "I am on the Internet.\n",
      "how am i\n",
      "Radical, let's get to booking! When did you want to leave?\n",
      "what?\n",
      "Blue\n",
      "boo\n",
      "two boll weevils grew up in s. carolina. one took off to hollywood and became a rich star. the other stayed in carolina and never amounted to much -- and naturally became known as the lesser of two weevils.\n",
      "I'd like to book a vacation!\n",
      "I can help you with that. Where are you traveling to?\n",
      "I'll go to Vancouver\n",
      "Where are you leaving from?\n",
      "I'll leave from Toronto\n",
      "When did you want to leave?\n",
      "I want to leave tomorrow! so let's say July 8th\n",
      "What should I set for return date?\n",
      "Let's set that for August 8th\n",
      "How much are you willing to spend on this trip?\n",
      "lets keep it under 3000\n",
      "So to recap, you want to book a trip from Toronto to Vancouver for 2020-07-08 00:00:00 to 2020-08-08 00:00:00 and you have a budget of 3000. If this is correct, please say yes, if not, say no\n",
      "yes\n",
      "Excellent, let's, see what the system says. Loading...\n",
      "Unfortunately there are no flights to Vancouver at this time.\n",
      "[400]\n",
      "\n",
      "bye\n",
      "Bye for now\n"
     ]
    }
   ],
   "source": [
    "Traveller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM4cjhaUZNAgkmIw8uFAKE4",
   "collapsed_sections": [
    "_q5ud27D_tsj",
    "vXVj9VDlAP_y",
    "sUbrUcDQDk4Y",
    "SSWb5SvtH2m6"
   ],
   "name": "Travel_Chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
