{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chatbot_Attempt1.ipynb","provenance":[],"authorship_tag":"ABX9TyPRq2dchwI0yZNpfdOXOE1a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"SHE0q7GQ-19k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1592488467125,"user_tz":240,"elapsed":30360,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"a007449c-a145-461c-e47b-f5875a3e11b2"},"source":["# We'll first need the data from my drive.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wYtec10h-phm","colab_type":"text"},"source":["# Outline\n","\n","I'm going to attempt to build a simple chatbot a a simple set of intents and see how I can improve it after. \n","\n","My thought is to create a list of global variables, which get filled as the person says things. I can have the machine pick out Named entities and ask questions about information it doesn't have, as it gets information.\n","\n","Latest Idea: write out a bunch of responses that the chatbot can have \n","based on what the user writes. Presently, I'm thinking that the responses should be based on what information the user provides. For example, say the user provides in their sentence a place they want to go and their budget. The bot would then ask, \"Okay, so you would like to go to {{this place}} and have a budget of {{this much}}. Where will you be travelling from and what date would you like to leave?\" "]},{"cell_type":"markdown","metadata":{"id":"A5KJsMrXXQV_","colab_type":"text"},"source":["## Pseudocode\n","\n","May be updated periodically"]},{"cell_type":"markdown","metadata":{"id":"CtAZpky2XYHo","colab_type":"text"},"source":["* import packages needed\n","* import data\n","* import intents\n","* tokenize data\n","* give a label to words using NER \n","* train to recognize what information is contained in the sentence to give the correct response. \n","  * This also entails recognizing whether the city stated is the origin or destination city\n","  * This should be able to handle budgets of all types, even no budget\n","  * We also need to be able to handle a variation of dates, and pick out the start and end dates\n","* Hard code some responses to the various permutations of data that is collected for each user question/statement.\n","  * Greeting\n","  * Greeting + Statement/Question relating to booking\n","  * Greeting + general question/statement\n","  * General question/statement\n","  * Statement/Question relating to booking\n","  * confirmations/rejections\n","  * conversation terminations\n","* The conversation should continue until the termination step\n"]},{"cell_type":"markdown","metadata":{"id":"3nZd4I-prDwH","colab_type":"text"},"source":["# Simple Chatbot"]},{"cell_type":"markdown","metadata":{"id":"92rjL9Q5rG5R","colab_type":"text"},"source":["## Get data, and train the model"]},{"cell_type":"code","metadata":{"id":"b2KhvI86_nqG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1592414985386,"user_tz":240,"elapsed":474,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"d8dce7e2-29d5-4606-cb4a-1be4303dd55d"},"source":["# We'll need the following nltk packages\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","# We'll use lemmas instead of stems.\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# We'll need json to open a file of intents\n","import json\n","\n","# We will need to save the model\n","import pickle\n","\n","# Some helper libraries\n","import numpy as np\n","import random\n","\n","# We'll need these to actually create a machine learning model.\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from keras.optimizers import SGD"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L2ShpzyHGuQ6","colab_type":"code","colab":{}},"source":["# this list will be for a bunch of tokenized words\n","words=[]\n","# this list is to contain the list of tags contained in the intents. This means the high level characterization of any interactions\n","classes = []\n","# This will be a list of tuples which will classify words with their tags.\n","documents = []\n","# pieces of speech and text to ignore\n","ignore_words = ['?', '!', ',',\"'s\"]\n","# This is our initial intents file\n","data_file = open('/content/drive/My Drive/1000ml/Project 7 - Chatbot/Data/intents.json').read()\n","intents = json.loads(data_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VZcy0rOkV4wv","colab_type":"code","colab":{}},"source":["# We will loop through the intents in the json file\n","for intent in intents['intents']:\n","    # Now loop through the actual possible text patterns \n","    for pattern in intent['patterns']:\n","\n","        # take each word and tokenize it\n","        w = nltk.word_tokenize(pattern)\n","        words.extend(w)\n","        # adding documents\n","        documents.append((w, intent['tag']))\n","\n","        # adding classes to our class list\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WDFGeTSAV44H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1592416088659,"user_tz":240,"elapsed":266,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"76deb9c2-ea0b-4f00-e3af-1ad33259d1be"},"source":["# Lemmatize all the words that aren't in our list of things to ignore\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","# sort the words alphabetically\n","words = sorted(list(set(words)))\n","# sort classes alphabetically\n","classes = sorted(list(set(classes)))\n","\n","# print out for QA\n","print (len(documents), \"documents\")\n","\n","print (len(classes), \"classes\", classes)\n","\n","print (len(words), \"unique lemmatized words\", words)\n","\n","# pickle some things to save them for later\n","pickle.dump(words,open('words.pkl','wb'))\n","pickle.dump(classes,open('classes.pkl','wb'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["37 documents\n","7 classes ['budget', 'date', 'goodbye', 'greeting', 'options', 'thanks', 'travel_plans']\n","57 unique lemmatized words ['a', 'anyone', 'are', 'awesome', 'be', 'book', 'budget', 'bye', 'can', 'chatting', 'could', 'date', 'day', 'do', 'for', 'good', 'goodbye', 'have', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hola', 'how', 'i', 'is', 'later', 'like', 'me', 'money', 'next', 'nice', 'of', 'offered', 'on', 'only', 'plane', 'provide', 'see', 'somewhere', 'spend', 'support', 'thank', 'thanks', 'that', 'there', 'this', 'till', 'time', 'to', 'travel', 'trip', 'want', 'what', 'you']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aPz71stuV42J","colab_type":"code","colab":{}},"source":["# In this cell we are creating our training data. It is basically creating a word vector for each word, and corresponding class vector\n","# initializing training data\n","training = []\n","output_empty = [0] * len(classes)\n","for doc in documents:\n","    # initializing bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","    # lemmatize each word - create base word, in attempt to represent related words\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","    # create our bag of words array with 1, if word match found in current pattern\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    # output is a '0' for each tag and '1' for current tag (for each pattern)\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training.append([bag, output_row])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssm8WtHfZkFx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592416778311,"user_tz":240,"elapsed":240,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"c682b4e6-5141-404f-9fec-8a155989a7ac"},"source":["# shuffle our features and turn into np.array. This appears as though it would make learning a little less biased.\n","random.shuffle(training)\n","training = np.array(training)\n","# create train and test lists. X - patterns, Y - intents\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","print(\"Training data created\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training data created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mPYV8X-YcFg9","colab_type":"code","colab":{}},"source":["# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n","# equal to number of intents to predict output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9QEOyQQcFqE","colab_type":"code","colab":{}},"source":["# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","#fitting and saving the model\n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n","model.save('chatbot_model.h5', hist)\n","\n","print(\"model created\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DKSLUxtNcFnY","colab_type":"text"},"source":["## Reload the saved model and try out the chatbot"]},{"cell_type":"code","metadata":{"id":"8PEzd_64cFkO","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","model = load_model('chatbot_model.h5')\n","import json\n","import random\n","intents = json.loads(open('/content/drive/My Drive/1000ml/Project 7 - Chatbot/Data/intents.json').read())\n","words = pickle.load(open('words.pkl','rb'))\n","classes = pickle.load(open('classes.pkl','rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KZrxjLAacFee","colab_type":"code","colab":{}},"source":["def clean_up_sentence(sentence):\n","    '''This function takes in a sentence, splits it into words, lemmatizes them and returns the list of words.'''\n","    sentence_words = nltk.word_tokenize(sentence)\n","    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n","    return sentence_words\n","\n","# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n","def bow(sentence, words, show_details=True):\n","    '''This function takes in a sentence, a bunch of words and returns a bag of words for words present in that sentence.'''\n","    # tokenize the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","    # bag of words - matrix of N words, vocabulary matrix\n","    bag = [0]*len(words)\n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s:\n","                # assign 1 if current word is in the vocabulary position\n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","    return(np.array(bag))\n","\n","def predict_class(sentence, model):\n","    ''''''\n","    # filter out predictions below a threshold\n","    p = bow(sentence, words,show_details=False)\n","    res = model.predict(np.array([p]))[0]\n","    ERROR_THRESHOLD = 0.25\n","    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n","    return return_list\n","\n","def getResponse(ints, intents_json):\n","    tag = ints[0]['intent']\n","    list_of_intents = intents_json['intents']\n","    for i in list_of_intents:\n","        if(i['tag']== tag):\n","            result = random.choice(i['responses'])\n","            break\n","    return result\n","\n","def chatbot_response(msg):\n","    ints = predict_class(msg, model)\n","    res = getResponse(ints, intents)\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YiBkHHWsx2X4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592422608276,"user_tz":240,"elapsed":303,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"1a9a6db5-96f8-410c-94ce-50dbe299b06d"},"source":["chatbot_response('I can only spend 1800')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Okay, I'll see what I can find.\""]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"5WmodJMMzcBi","colab_type":"text"},"source":["## The GUI"]},{"cell_type":"code","metadata":{"id":"RiLIDOqVxWun","colab_type":"code","colab":{}},"source":["#Creating GUI with tkinter\n","import tkinter\n","from tkinter import *\n","\n","\n","def send():\n","    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n","    EntryBox.delete(\"0.0\",END)\n","\n","    if msg != '':\n","        ChatLog.config(state=NORMAL)\n","        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n","        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n","\n","        res = chatbot_response(msg)\n","        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n","\n","        ChatLog.config(state=DISABLED)\n","        ChatLog.yview(END)\n","\n","\n","base = Tk()\n","base.title(\"Hello\")\n","base.geometry(\"400x500\")\n","base.resizable(width=FALSE, height=FALSE)\n","\n","#Create Chat window\n","ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n","\n","ChatLog.config(state=DISABLED)\n","\n","#Bind scrollbar to Chat window\n","scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n","ChatLog['yscrollcommand'] = scrollbar.set\n","\n","#Create Button to send message\n","SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n","                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n","                    command= send )\n","\n","#Create the box to enter message\n","EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n","#EntryBox.bind(\"<Return>\", send)\n","\n","\n","#Place all components on the screen\n","scrollbar.place(x=376,y=6, height=386)\n","ChatLog.place(x=6,y=6, height=386, width=370)\n","EntryBox.place(x=128, y=401, height=90, width=265)\n","SendButton.place(x=6, y=401, height=90)\n","\n","base.mainloop()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EVuJ5KcUxXOf","colab_type":"text"},"source":["## Try a bigger list of intents"]},{"cell_type":"code","metadata":{"id":"skJApBpJxXR3","colab_type":"code","colab":{}},"source":["from pprint import pprint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SOi57hsQxXUC","colab_type":"code","colab":{}},"source":["data_file = open('/content/drive/My Drive/1000ml/Project 7 - Chatbot/Data/frames.json').read()\n","intents = json.loads(data_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZHM0lCI0n-Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592425107844,"user_tz":240,"elapsed":251,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"c7bdd816-5177-41f5-b58c-ff475e21f147"},"source":["intents[1]['turns'][1]['text']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Hi. Sorry, I can't find any trips from Gotham City to Mos Eisley for you.\""]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"eWIVtCDu0oEM","colab_type":"text"},"source":["# Better Chatbot\n","\n","For this, we'll take the above chatbot and expand a little bit. I'm going to see what happens if the tags that I give my words are generated from the SpaCy library, rather than hardcoding them. We will use the list of interactions between users and computer in the frames dataset. "]},{"cell_type":"code","metadata":{"id":"ARl2VAq_0oBc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1592491605410,"user_tz":240,"elapsed":343,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"0398ac35-5744-40be-8850-9c043c4c3ee3"},"source":["# We'll need spacy for this, and some packages within\n","import spacy\n","from spacy import displacy\n","from collections import Counter\n","import en_core_web_sm\n","\n","# We'll need the following nltk packages\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","# We'll use lemmas instead of stems.\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# We'll need to get rid of punctuation for a cleaner set of words\n","import re\n","\n","# We'll need json to open a file of intents\n","import json\n","\n","# We will need to save the model\n","import pickle\n","\n","# Some helper libraries\n","import numpy as np\n","import random\n","\n","# We'll need these to actually create a machine learning model.\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from keras.optimizers import SGD\n","\n","# For timing some loops\n","import time"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bx1yLC9k8iGw","colab_type":"code","colab":{}},"source":["# This is how we will process the data.\n","nlp = en_core_web_sm.load()\n","# this list will be for a bunch of tokenized words\n","words = []\n","# this list is to contain the list of tags contained in the intents. This means the high level characterization of any interactions\n","classes = []\n","# This will be a list of tuples which will classify words with their tags, which we will make using SpaCy.\n","documents = []\n","# pieces of speech and text to ignore\n","ignore_words = ['?', '!']\n","# This is our initial intents file\n","data_file = open('/content/drive/My Drive/1000ml/Project 7 - Chatbot/Data/frames.json').read()\n","intents = json.loads(data_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZaQe7asf-mGd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592491828052,"user_tz":240,"elapsed":1134,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"171ae08c-b458-4850-d513-a9a3f1600b01"},"source":["# The intents are defined, but the file is huge and contains a bunch of precategorized data. For ease and to avoid potential bias, let's organize the json file into\n","# a dictionary of just the conversation, and the replies. \n","# To do this, we only want to take what the user says, and follow it up with a response.\n","new_intents = []\n","starttime = time.time()\n","# First, we'll loop through each conversation\n","for intent in intents:\n","  # Then within each conversation, we'll need to loop through the turns\n","  for t in range(0,len(intent['turns'])-1,2):\n","    new_intents.append({\n","                        'user':re.sub(r'[^a-zA-Z0-9\\s]', ' ', intent['turns'][t]['text']),\n","                        'response':re.sub(r'[^a-zA-Z0-9\\s]', ' ', intent['turns'][t+1]['text'])\n","                        })\n","# Just testing how long this takes. \n","endtime= time.time()\n","print(f'{endtime-starttime} seconds   OR   {(endtime-starttime)/60} minutes')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.059102773666381836 seconds   OR   0.0009850462277730305 minutes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zTMgFWR4zdxx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592491828060,"user_tz":240,"elapsed":362,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"ae0dee7f-952a-4891-ef23-7c89fe8e9fab"},"source":["new_intents[1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'response': 'I checked the availability for this date and there were no trips available   Would you like to select some alternate dates ',\n"," 'user': 'Yes  how about going to Neverland from Caprica on August 13  2016 for 5 adults  For this trip  my budget would be 1900 '}"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Rj3LuKB0Hk2p","colab_type":"text"},"source":["The next step here is to take out all the user questions and break them down into words, and give them each a tag as per PoS tags with SpaCy."]},{"cell_type":"code","metadata":{"id":"-XbCX-f48iOm","colab_type":"code","colab":{}},"source":["# For this, we will treat every back and forth as a question and response. The user is always considered the question, while the wizard or computer is considered the response\n","# We will loop through the intents in the json file\n","for intent in new_intents:\n","    # Now we want to pull out the user half of the conversation\n","    pattern_user = intent['user']\n","    # Then the response half of the conversation\n","    pattern_response = intent['response']\n","    # take each word and tokenize it\n","    w_u = nltk.word_tokenize(pattern_user)\n","    w_r = nltk.word_tokenize(pattern_response)\n","    words.extend(w_u)\n","    words.extend(w_r)\n","    # adding documents\n","    documents.append((w_u, 'question'))\n","    documents.append((w_r, 'response'))\n","\n","# adding classes to our class list\n","classes.append('question')\n","classes.append('response')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KI44SUeP8iSn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1592491832856,"user_tz":240,"elapsed":2512,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"45ae49d2-8f88-4183-bab8-10a9681d683a"},"source":["# Lemmatize all the words that aren't in our list of things to ignore\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","# sort the words alphabetically\n","words = sorted(list(set(words)))\n","# sort classes alphabetically\n","classes = sorted(list(set(classes)))\n","\n","# print out for QA\n","print (len(documents), \"documents\")\n","\n","print (len(classes), \"classes\", classes)\n","\n","print (len(words), \"unique lemmatized words\", words)\n","\n","# pickle some things to save them for later\n","pickle.dump(words,open('words.pkl','wb'))\n","pickle.dump(classes,open('classes.pkl','wb'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["19158 documents\n","2 classes ['question', 'response']\n","6361 unique lemmatized words ['0', '00', '000', '0042', '00a', '00am', '00p', '00pm', '01am', '01pm', '02', '02pm', '03pm', '04', '05', '06', '07', '09', '0usd', '1', '10', '100', '1000', '10000', '1001', '1002', '1003', '10036', '10042', '1006', '1007', '1008', '10081', '1012', '1013', '1018', '10199', '10254', '10269', '10300', '10317', '1032', '1035', '1037', '10377', '10392', '10400', '1041', '1044', '1047', '10474', '1048', '1049', '1050', '1051', '1052', '10540', '10546', '1056', '1057', '1058', '10586', '1059', '1061', '1062', '1065', '10656', '1066', '10688', '1069', '1071', '1072', '10737', '10747', '1075', '10757', '1078', '10800', '1081', '1082', '1085', '1086', '1087', '1088', '10887', '10898', '10905', '1091', '10932', '1095', '10956', '1096', '1098', '10986', '10th', '10usd', '11', '110', '1100', '1103', '1105', '1106', '1108', '1109', '11095', '1112', '1113', '11161', '11168', '11185', '1119', '11190', '1123', '1126', '11278', '1128', '1129', '1130', '11300', '11309', '11317', '1132', '1134', '11385', '1140', '11400', '1141', '1142', '1144', '1145', '11450', '11457', '11460', '1148', '11505', '11513', '1152', '11540', '1155', '1156', '1157', '11600', '1162', '1163', '1164', '1166', '11663', '1168', '1169', '1172', '11748', '1176', '11787', '1181', '11812', '11822', '1184', '1189', '11900', '1191', '11941', '11981', '11am', '11th', '11usd', '12', '1200', '12006', '1201', '12012', '1202', '12052', '12081', '1213', '12167', '1217', '1219', '1221', '1225', '1226', '1229', '1230', '12306', '12316262', '1232', '12339', '1234', '1236', '12367', '12376', '12388', '1239', '12400', '1242', '12443', '12451', '12474', '12492', '12493', '12496', '1250', '12500', '1252', '1255', '12553usd', '12555', '12556', '1256', '1260', '12600', '1262', '1264', '12692', '127', '1271', '12725', '12758', '1277', '1278', '1279', '12800', '12824', '1283', '1284', '1285', '12853', '12873', '1290', '1291', '12919', '12934', '1295', '1296', '12980', '12pm', '12th', '12usd', '13', '1300', '13000', '13024', '1304', '13047', '13056', '1306', '1309', '13100', '1311', '1313', '1318', '1319', '13194', '1320', '13200', '1323', '1324', '13263', '1327', '1328', '1329', '13293', '1332', '1333', '13349', '13384', '1342', '1349', '13494', '1350', '13500', '1354', '1355', '1356', '1358', '1363', '1364', '13646', '1366', '13662', '13685', '13700', '1372', '1375', '1377', '13776', '13800', '13805', '1382', '13835', '1384', '13867', '1388', '1389', '1392', '1397', '13976', '13day', '13th', '13usd', '14', '1400', '14000', '14048', '14057', '1411', '14111', '1415', '1416', '1420', '14200', '14235', '14258', '14268', '1427', '1428', '1429', '1430', '1434', '1444', '14481', '14513', '1453', '1454', '1455', '1461', '1465', '14700', '1474', '1477', '148', '14800', '14828', '1483', '1484', '1486', '14863', '1487', '1490', '14900', '14924', '14931', '1495', '1497', '14th', '14usd', '15', '150', '1500', '15000', '1502', '1504', '15057', '1507', '15100', '1511', '15134', '152', '15200', '1522', '1523', '15241', '15243', '1525', '15279', '1528', '153', '1530', '15300', '1531', '1538', '15395', '15399', '1542', '15441', '1547', '15506', '15508', '1553', '15535', '1554', '1555', '15570', '1558', '15600', '1561', '1563', '1564', '1566', '1568', '1571', '1572', '15754', '1582', '1583', '1586', '15883', '1589', '15900', '15910', '1598', '15th', '15usd', '16', '1600', '16000', '1606', '1607', '16078', '1608', '1609', '16097', '1611', '16111', '1613', '16174', '1618', '16223', '1624', '1627', '1630', '16320', '1633', '1634', '16364', '1637', '16389', '1639', '1640', '16400', '16431', '16434', '1644', '16500', '1651', '1653', '1654', '1657', '1660', '16600', '16602', '1661', '1665', '1666', '1668', '1669', '16699', '167', '16700', '1673', '16738', '1675', '16788', '1684', '16843', '1685', '1691', '1692', '16969', '1698', '16th', '16usd', '17', '1700', '17000', '1703', '1705', '1707', '1709', '17094', '1710', '17100', '1711', '17127', '1717', '17200', '1721', '17223', '1723', '17230', '1725', '1728', '17296', '1731', '1732', '1735', '1738', '1739', '17400', '1743', '1745', '17460', '17462', '17467', '1747', '175', '1751', '1752', '1755', '1758', '17600', '1761', '17611', '17619', '1763', '1764', '1767', '1769', '177', '1772', '178', '1780', '1783', '17834', '1785', '1787', '1790', '17900', '17903', '1793', '17am', '17th', '17usd', '18', '1800', '1801', '1805', '1806', '1807', '1808', '1809', '18100', '1811', '18155', '1817', '18186', '1819', '18194', '182', '1822', '1831', '1832', '1834', '1837', '18385', '18400', '18412', '1845', '18451', '1846', '18463', '1847', '1849', '1855', '1857', '1858', '186', '18600', '18607', '1861', '1863', '1865', '1866', '18702', '1872', '1874', '1875', '18762', '18789', '1879', '188', '1881', '1883', '1886', '18888', '189', '1890', '18927', '1894', '1899', '18th', '18usd', '19', '1900', '19000', '19028', '1906', '1907', '1910', '1911', '19135', '1914', '1916', '1919', '192', '1924', '19293', '19295', '193', '1930', '19308', '1931', '1932', '1934', '1936', '1942', '1943', '1947', '19500', '1951', '1952', '1953', '1955', '1956', '19573', '1960', '19615', '1965', '1967', '19674', '1969', '197', '1971', '19719', '1972', '19735', '19736', '1975', '1986', '1987', '1989', '19900', '1991', '1992', '19923', '1996', '1999', '19th', '19usd', '1h', '1st', '1usd', '2', '20', '200', '2000', '20000', '20009', '2002', '2006', '20067', '2009', '20100', '2011', '2012', '20145', '2016', '20167', '2018', '20181', '2019', '20200', '2021', '2022', '2024', '2025', '2026', '2028', '2029', '20297', '2031', '20354', '2037', '204', '2040', '2044', '2045', '2046', '2048', '2049', '2052', '20525', '2054', '2056', '2058', '2059', '20697', '2070', '2072', '20741', '2075', '20805', '20806', '2085', '2086', '2089', '20900', '2094', '2095', '2096', '20967', '2097', '20th', '20usd', '21', '2100', '2101', '21031', '2104', '2107', '2110', '21100', '2112', '2113', '2115', '2119', '2122', '2127', '2129', '2132', '2134', '2135', '2145', '21452', '2146', '2149', '2150', '2151', '2153', '21536', '2154', '2157', '2159', '2161', '2162', '2164', '2167', '2170', '2171', '2172', '2177', '2179', '21803', '21807318', '2181', '2182', '2183', '219', '2190', '2191', '2192', '2194', '2196', '2197', '2199', '21st', '21usd', '22', '2200', '2203', '2204', '2210', '22100', '22102', '2214', '22183', '2219', '22218', '2224', '2225', '2227', '22308558', '2233', '2234', '2236', '22382', '22400', '22417', '2242', '22481', '2251', '22510', '2254', '22590', '2262', '2265', '2266', '2267', '2269', '2272', '2274', '2275', '2278', '228', '2281', '2281usd', '2282', '2284', '2285', '2289', '2290', '2292', '2293', '22931', '2296', '2297', '22nd', '22usd', '23', '2300', '2308', '2311', '2312', '2313', '2314', '2315', '2317', '2320', '2325', '2326', '2330', '23300', '2333', '2335', '2336', '2337', '23400', '2342', '23460', '2349', '235', '23500', '2351', '2353', '2358', '2362', '2365', '2366', '23688', '2369', '2370', '23700', '2371', '2373', '2374', '2375', '2378', '2381', '23813', '2390', '2393', '23961', '23rd', '23usd', '24', '2400', '2401', '2403', '24044', '2408', '24096', '2413', '2415', '24162', '2417', '2418', '2420', '2423', '2426', '24294', '24300', '2434', '2435', '2437', '2439', '2441', '2442', '2443', '2444', '2446', '2449', '2450', '24501', '2454', '2455', '2459', '2460', '2461', '2463', '2464', '2465', '2466', '2470', '2471', '2472', '2473', '24739', '2474', '2475', '2477', '24786', '2480', '2483', '2487', '2488', '2490', '2495', '24951', '2497', '2498', '2499', '24st', '24th', '24usd', '25', '2500', '2502', '2504', '2505', '2507', '2514', '2521', '2523', '2527', '2528', '25300', '2532', '2533', '2534', '2536', '25367', '2537', '2538', '2541', '2546', '25500', '2551', '2553', '2555', '2556', '25600', '2565', '2568', '2572', '2581', '25812', '2582', '2584', '2589', '259', '2594', '2596', '2597', '2598', '25th', '25usd', '26', '2600', '2600usd', '2602', '2603', '2605', '2606', '2607', '261', '2610', '2612', '2613', '2615', '2616', '2619', '2624', '2625', '2628', '2629', '263', '2630', '2632', '2633', '2634', '2645', '2648', '265', '2652', '2656', '26573usd', '2660', '2662', '2666', '2667', '2670', '26719', '2672', '26733', '2674', '2675', '26775', '2678', '2679', '2683', '2684', '2686', '2689', '2690', '2691', '2694', '2695', '2698', '2699', '26th', '26usd', '27', '270', '2700', '2701', '2703', '2705', '2706', '27100', '2715', '2718', '2720', '2722', '27240', '2726', '2729', '2732', '2740', '2742', '27447', '2747', '2749', '27500', '2751', '2752', '2753', '2754', '2757', '2758', '2759', '2762', '2764', '2767', '2771', '2773', '2774', '2775', '2781', '27810', '2783', '27860', '2789', '2793', '2794', '2797', '2799', '27th', '27usd', '28', '2800', '2801', '2802', '2803', '2809', '2810', '2813', '2814', '2815', '2816', '2819', '28237', '2825', '2834', '2835', '2837', '2838', '2843', '2848', '28500', '2853', '28554', '2856', '2857', '2860', '2861', '2863', '28631', '2866', '2868', '2870', '2871', '2877', '2880', '2881', '2882', '2885', '2886', '28864', '2888', '2890', '2893', '28nd', '28th', '28usd', '29', '290', '2900', '29000', '2903', '2905', '2906', '2908', '2917', '2918', '292', '29232', '2925', '29251', '2926', '293', '2933', '2934', '2936', '2945', '2946', '2949', '2952', '2953', '2954', '2956', '2961', '2963', '2964', '2967', '2968', '2976', '2980', '2981', '29810', '2983', '2985', '2986', '2990', '2993', '2994', '2995', '2998', '29th', '29usd', '2am', '2g', '2nd', '2pm', '2usd', '3', '30', '300', '3000', '3000usd', '3001', '30025', '3006', '3013', '3015', '30151', '3016', '3019', '3020', '30229', '3023', '3024', '3025', '303', '3030', '30300', '3031', '3032', '3033', '30332', '3034', '3036', '3039', '30399', '3043', '3046', '3047', '3048', '3049', '3050', '3051', '3052', '306', '3064', '30657', '3066', '3067', '3070', '3071', '3072', '3073', '3085', '3087', '3088', '3091', '3094', '3096', '3097', '3099', '30am', '30th', '30usd', '31', '3100', '3100usd', '3103', '3104', '3106', '3107', '3108', '311', '31122', '3113', '31138', '3119', '3120', '3121', '3122', '3123', '3128', '3130', '3131', '3134', '3138', '31400', '3141', '3144', '3145', '3148', '31500', '3152', '3153', '3155', '3158', '316', '3164', '3167', '3170', '3171', '3174', '3176', '3179', '3180', '3182', '3188', '3192', '3196', '3197', '31st', '31th', '31usd', '32', '3200', '3201', '3206', '3207', '3208', '3209', '3211', '3217', '32198', '3228', '3229', '32291', '323', '3233', '3238', '3240', '32400', '3244', '3249', '3250', '3258', '3259', '3261', '3263', '3265', '3266', '3272', '3276', '32800', '3281', '3282', '3284', '3287', '3288', '3289', '329', '32900', '3294', '3299', '32am', '32usd', '33', '3300', '3309', '3314', '3315', '332', '3326', '3328', '3331', '3332', '3333', '3334', '3339', '3340', '3341', '3344', '3345', '3348', '3354', '3355', '3364', '3369', '3370', '3372', '3374', '3375', '3377', '3378', '3384', '3385', '3386', '33900', '3393', '3396', '33usd', '34', '340', '3400', '3401', '3408', '341', '3410', '3414', '3415', '342', '3420', '3421', '3422', '3424', '3426', '3428', '34300', '3434', '3435', '3436', '3442', '3451', '3453', '3456', '3458', '3460', '3462', '3463', '3464', '3465', '347', '3474', '3477', '3480', '34800', '3487', '3491', '3493', '3494', '3495', '3499', '34pm', '34usd', '35', '3500', '3505', '3506', '3508', '351', '3510', '35118', '3515', '35200', '3522', '3524', '3529', '3530', '3534', '35400', '3547', '3549', '3550', '3553', '3557', '3558', '356', '3564', '3565', '3566', '3572', '3576', '3577', '3578', '35780', '3580', '3583', '3585', '3587', '359', '3591', '3593', '3597', '3598', '35m', '35usd', '36', '3600', '3602', '3603', '3604', '3610', '3612', '3616', '3618', '362', '3629', '36300', '3631', '3639', '3642', '3649', '365', '3651', '3653', '3657', '3658', '366', '3661', '3662', '36625usd', '3663', '3666', '36667', '3668', '3677', '368', '3680', '3685', '3698', '3699', '36am', '36pm', '36usd', '37', '3700', '3702', '3707', '3708', '3709', '3713', '3715', '3717', '3722', '3723', '3724', '3726', '3727', '3731', '37321', '3735', '3739', '3741', '3743', '3753', '37600', '3762', '3767', '3770', '3771', '3775', '3781', '3787', '3793', '3794', '3798', '37am', '37pm', '37usd', '38', '3800', '3801', '3804', '3808', '381', '3813', '3814', '3815', '3822', '3823', '3824', '3827', '3828', '3837', '3839', '384', '3840', '3841', '3843', '385', '3853', '3857', '3862', '387', '38736', '3886', '3888', '3889', '3893', '3895', '38usd', '39', '3900', '3907', '3916', '392', '3931', '3933', '3942', '3947', '3952', '3955', '3960', '3961', '3965', '39694', '3971', '3976', '398', '3983', '3984', '3988', '399', '3995', '3998', '39usd', '3am', '3pm', '3rd', '3usd', '4', '40', '400', '4000', '4002', '4006', '4010', '4012', '4018', '4020', '4030', '4038', '4039', '4041', '4045', '4046', '4047', '4050', '4054', '4059', '4063', '4069', '407', '4076', '4077', '4084', '4085', '4086', '4098', '40usd', '41', '4100', '4102', '4113', '4119', '413', '4130', '4131', '4142', '4144', '4148', '4153', '4159', '4160', '4162', '4164', '4166', '4168', '41753', '4176', '4178', '4180', '419', '4195', '4198', '4199', '41usd', '42', '4200', '4202', '4204', '4209', '4214', '4215', '4216', '4217', '4219', '4220', '4227', '4234', '4235', '4237', '42409', '4243', '4249', '4253', '426', '4261', '4265', '4266', '4268', '427', '4271', '4277', '428', '4283', '4289', '42usd', '43', '4300', '4300usd', '4301', '4304', '4319', '4329', '433', '4331', '4334', '4335', '4339', '43500', '4353', '4358', '4361', '4366', '4386', '4388', '4390', '43usd', '44', '4400', '4405', '4407', '4411', '4414', '4415', '442', '4420', '4421', '4446', '4453', '4454', '4457', '4461', '4473', '4476', '4479', '4481', '4484', '4485', '4489', '4495', '44usd', '45', '4500', '4501', '450usd', '4517', '4525', '4531', '4535', '4543', '4550', '4557', '4569', '4576', '4584', '4586', '45usd', '46', '4600', '4601', '4608', '4609', '4613', '4615', '4616', '4628', '4635', '4637', '4638', '464', '4644', '4645', '4653', '4661', '4667', '4674', '4679', '469', '4695', '4697', '46am', '46usd', '47', '4700', '4702', '4707', '4709', '4719', '472', '4722', '4729', '4731', '474', '475', '4751', '4753', '476', '4762', '477', '4770', '4771', '4773', '4783', '479', '47usd', '48', '4800', '4808', '481', '4810', '483', '4834', '4840', '4846', '4851', '4853', '4885', '4887', '4889', '489', '4892', '4897', '4898', '48usd', '49', '490', '4900', '4921', '493', '4930', '4942', '4959', '4961', '4963', '4966', '497', '4977', '4982', '4987', '4990', '4991', '49usd', '4days', '4pm', '4th', '4usd', '5', '50', '500', '5000', '5003', '500usd', '5016', '502', '5035', '507', '5092', '50lb', '50usd', '51', '5100', '5107', '511', '5122', '5135', '5143', '5144', '515', '516', '5160', '5168', '5173', '5176', '5179', '5187', '519', '51it', '51usd', '52', '5200', '5203', '5208', '5212', '5218', '5223', '523', '5236', '5241', '527', '5279', '5288', '5295', '52usd', '53', '5300', '5301', '5306', '5315', '532', '5321', '534', '5347', '5348', '5385', '539', '5393', '53usd', '54', '5400', '5407', '543', '5440', '5445', '54474', '545', '5462', '54700', '5474', '548', '5486', '54usd', '55', '550', '5500', '5506', '550usd', '5512', '5513', '5529', '553', '5530', '5531', '554', '5554', '5555', '556', '5561', '5564', '5569', '5579', '5589', '5591', '55usd', '56', '5600', '5619', '564', '5646', '5649', '565', '5651', '5653', '5664', '5678', '5684', '569', '5695', '56a', '56pm', '56usd', '57', '5700', '5714', '5716', '572', '5725', '5744', '575', '57520', '576', '5764', '577', '5775', '5777', '5789', '57usd', '58', '5800', '581', '5812', '583', '5831', '5841', '5844', '585', '5878', '588', '5881', '5894', '58usd', '59', '5931', '5933', '594', '595', '5952', '598', '59usd', '5g', '5higher', '5th', '5usd', '6', '60', '600', '6000', '6003', '6009', '6014', '603', '6067', '607', '6077', '6085', '6088', '60usd', '61', '610', '6100', '611', '612', '6125', '6159', '616', '6166', '617', '6178', '619', '61usd', '62', '6200', '6206', '6228', '623', '6249', '6251', '6255', '6273', '6276', '6289', '629', '62usd', '63', '630', '6300', '632', '6326', '633', '6330', '6344', '6346', '6347', '635', '6351', '6362', '637', '6371', '6373', '63usd', '64', '640', '6400', '6402', '6412', '645', '646', '6467', '6480', '6490', '6493', '6494', '64usd', '65', '6500', '651', '6518', '6540', '655', '656', '658', '65usd', '66', '660', '6600', '6606', '6621', '6632', '6642', '665', '666', '667', '668', '6687', '6697', '66usd', '67', '6700', '6704', '6725', '673', '674', '676', '679', '67usd', '68', '6800', '681', '6810', '6812', '682', '683', '684', '685', '687', '6878', '6887', '68us', '68usd', '69', '6900', '692', '69238', '694', '6941', '698', '6988', '6988usd', '6992', '69usd', '6am', '6th', '6usd', '7', '70', '700', '7000', '700usd', '701', '7017', '703', '704', '706', '7090', '70usd', '71', '710', '7100', '711', '7119', '712', '7141', '7146', '717', '7184', '7185', '71usd', '72', '720', '721', '7214', '7231', '724', '7258', '7282', '729', '7290', '72usd', '73', '7300', '7314', '7321', '7328', '733', '7335', '734', '736', '737', '7377', '7392', '73usd', '74', '740', '7402', '7417', '743', '7460', '747', '7473', '74usd', '75', '7500', '751', '752', '755', '7559', '7561', '7573', '758', '759', '75usd', '76', '7600', '761', '7649', '765', '766', '7661', '767', '76usd', '77', '7701', '7706', '771', '775', '7763', '778', '7796', '77usd', '78', '781', '7810', '7818', '785', '786', '787', '789', '7893', '78usd', '79', '7909', '791', '7910', '792', '793', '7944', '795', '7983', '7986', '79usd', '7am', '7th', '7usd', '8', '80', '800', '8000', '801', '8020', '804', '8044', '808', '809', '80usd', '81', '810', '8106', '812', '8135', '814', '8146', '815', '81usd', '82', '821', '823', '8230', '8275', '828', '829', '82usd', '83', '8300', '8308', '8316', '832', '8320', '833', '837', '838', '83usd', '84', '8418', '842', '843', '8438', '8445', '846', '8465', '847', '848', '84usd', '85', '8500', '8501', '851', '852', '853', '858', '85usd', '86', '8600', '861', '8616', '8652', '8664', '8666', '867', '868', '8681', '869', '86usd', '87', '871', '8723', '875', '8766', '877', '8778', '8783', '87usd', '88', '880', '8800', '881', '882', '8820', '8829', '884', '8843', '885', '887', '8871', '88usd', '89', '8900', '892', '8938', '894', '8942', '8962', '897', '8970', '8992', '89usd', '8am', '8th', '8usd', '9', '90', '900', '901', '903', '9031', '9043', '907', '9079', '909', '90usd', '91', '911', '9114', '914', '9141', '917', '918', '91usd', '92', '9200', '921', '924', '926', '9264', '92usd', '93', '930', '9300', '9324', '9341', '9355', '9362', '9364', '937', '938', '9382', '93usd', '94', '9400', '9416', '9449', '945', '9455', '9484', '94usd', '95', '9500', '9503', '9527', '953', '9550', '956', '957', '958', '959', '9596', '95usd', '96', '9610', '962', '9624', '9647', '968', '969', '96usd', '97', '970', '9700', '971', '973', '974', '9774', '9775', '9776', '9795', '97usd', '98', '9800', '982', '987', '98usd', '99', '990', '993', '994', '998', '99usd', '9am', '9pm', '9th', '9usd', 'a', 'ability', 'able', 'aboot', 'abound', 'about', 'above', 'abroad', 'absolute', 'absolutely', 'absulutely', 'abundantly', 'abut', 'accept', 'acceptable', 'accepted', 'access', 'accessible', 'acclaimed', 'accommodate', 'accommodates', 'accommodating', 'accommodation', 'accomodate', 'accomodation', 'accomodations', 'accompanied', 'accompaniment', 'accompanying', 'according', 'account', 'accurate', 'ace', 'across', 'action', 'activity', 'actual', 'actually', 'actulally', 'ad', 'add', 'added', 'addition', 'additional', 'additionally', 'address', 'addressing', 'adequate', 'adhere', 'adjust', 'admit', 'adulst', 'adult', 'advance', 'adventure', 'aegis', 'af', 'affect', 'affoord', 'afford', 'affordable', 'aficionado', 'aforementioned', 'afraid', 'africa', 'after', 'afternoon', 'afterwards', 'again', 'age', 'agency', 'agent', 'agghhh', 'ago', 'agree', 'ah', 'ahead', 'ahed', 'ahh', 'ahhh', 'ahhhh', 'aid', 'aiming', 'ain', 'aint', 'aire', 'airline', 'airplane', 'airport', 'aka', 'ala', 'alarming', 'albeit', 'alcohol', 'alcoholic', 'alcoholism', 'aleger', 'alegre', 'alegrie', 'alert', 'alexandria', 'alimony', 'all', 'alley', 'allo', 'allocate', 'allocated', 'allow', 'allowance', 'allowed', 'allows', 'allrighty', 'almost', 'alone', 'along', 'alpha', 'already', 'alright', 'alrighty', 'also', 'alternate', 'alternative', 'alternatively', 'although', 'altogether', 'always', 'am', 'amazeballs', 'amazing', 'ambition', 'amenity', 'america', 'ami', 'amidst', 'amigo', 'amistad', 'ammenities', 'amok', 'among', 'amor', 'amount', 'amtrak', 'amusement', 'an', 'ancestral', 'ancient', 'and', 'angel', 'angeles', 'angelic', 'angle', 'animal', 'anniversary', 'announce', 'anomaly', 'another', 'answer', 'answering', 'antartica', 'anther', 'anticipation', 'antique', 'antoni', 'antonio', 'antonioo', 'anwhere', 'anxious', 'any', 'anybody', 'anyone', 'anything', 'anythnig', 'anytime', 'anyway', 'anyways', 'anywehere', 'anywhere', 'apex', 'apologize', 'apology', 'apparently', 'appeal', 'appealing', 'appear', 'appearing', 'appears', 'appease', 'apple', 'application', 'apply', 'appreciate', 'appreciated', 'appropriate', 'approval', 'approve', 'approved', 'approximate', 'approximately', 'aquamarine', 'arbitrary', 'arc', 'archaeological', 'are', 'area', 'aren', 'arent', 'argentina', 'arm', 'around', 'arrange', 'array', 'arrival', 'arrive', 'arrives', 'arriving', 'art', 'artisanal', 'artist', 'arya', 'as', 'asap', 'ascertain', 'asia', 'asian', 'aside', 'ask', 'asked', 'asking', 'assessment', 'assist', 'assistance', 'assistant', 'associate', 'associated', 'assume', 'assuming', 'assure', 'assured', 'astronomical', 'at', 'atalanta', 'athens', 'atlanta', 'atlantah', 'atlante', 'atlantic', 'atlantis', 'atm', 'attached', 'attack', 'attempt', 'attending', 'attention', 'atthe', 'attitude', 'attract', 'attracting', 'attraction', 'attractive', 'aug', 'august', 'aunt', 'aurora', 'australia', 'author', 'automatically', 'autumn', 'avabilable', 'availabe', 'availability', 'availabities', 'available', 'availble', 'avenue', 'average', 'avialabilities', 'avialable', 'aviv', 'aw', 'await', 'awaits', 'award', 'aware', 'away', 'awayyyyy', 'awe', 'awesome', 'awful', 'awfully', 'aww', 'awwwwsome', 'ay', 'ayoooo', 'ayyy', 'azure', 'b', 'ba', 'babe', 'baby', 'bachelor', 'back', 'backpack', 'backpacking', 'backside', 'backstory', 'bad', 'badass', 'badly', 'bae', 'baech', 'bag', 'baked', 'bakery', 'balderdash', 'ball', 'ballpark', 'baltimore', 'bank', 'bar', 'barcelona', 'barcelonna', 'barely', 'bares', 'bargain', 'barkcelona', 'baron', 'barren', 'base', 'based', 'bash', 'basically', 'basin', 'bask', 'bathroom', 'battled', 'bay', 'bazaar', 'bbq', 'bday', 'be', 'beach', 'beachfront', 'beachside', 'bean', 'beanie', 'beat', 'beautiful', 'beautifully', 'beauty', 'because', 'become', 'bed', 'bedtime', 'beeeeeauuuuuuutiful', 'been', 'beer', 'before', 'beggar', 'begin', 'beginning', 'behind', 'behooves', 'beijing', 'being', 'bejing', 'belem', 'believe', 'believing', 'belly', 'belo', 'below', 'beltimore', 'beneath', 'benefit', 'benn', 'berlin', 'beside', 'best', 'bestest', 'bestie', 'besties', 'bet', 'betsy', 'better', 'betty', 'between', 'betweens', 'bevy', 'beyond', 'bh', 'bieber', 'biebs', 'big', 'biggest', 'bill', 'billboard', 'billed', 'billing', 'billion', 'binary', 'bind', 'bird', 'birmingham', 'birthday', 'bit', 'bitty', 'biz', 'blah', 'bleh', 'blessed', 'bleu', 'blew', 'blip', 'bliss', 'block', 'blocked', 'blog', 'blow', 'blueberry', 'bluff', 'blush', 'boast', 'boasting', 'boat', 'body', 'boi', 'bolivia', 'bon', 'bonjour', 'bonus', 'bonzai', 'boo', 'booing', 'book', 'booked', 'booking', 'bookit', 'boot', 'border', 'bored', 'boring', 'borrow', 'bos', 'boston', 'bot', 'both', 'bother', 'bothered', 'bought', 'bout', 'boutchu', 'boutique', 'boy', 'boyfriend', 'boyz', 'brady', 'brain', 'brainer', 'brand', 'brandon', 'brasilia', 'brass', 'brat', 'bratty', 'bratwurst', 'brazil', 'break', 'breakfast', 'breakfst', 'breaking', 'breakk', 'breakwater', 'breaky', 'breathtaking', 'breeding', 'breeeaaaakkkk', 'brew', 'brewery', 'bride', 'brien', 'brilliant', 'bring', 'bringing', 'brings', 'british', 'bro', 'broad', 'broke', 'bronze', 'brook', 'bros', 'brother', 'bruce', 'bruh', 'brutal', 'btw', 'buck', 'buckaroonies', 'bucket', 'bud', 'buddy', 'budget', 'budgetary', 'budgeted', 'budjet', 'buenos', 'buffet', 'buget', 'bugger', 'building', 'bull', 'bummer', 'bunch', 'bundle', 'burgeoning', 'burlington', 'burlingtonian', 'burly', 'burn', 'burnt', 'bus', 'busan', 'business', 'bustle', 'bustling', 'busy', 'but', 'butt', 'butter', 'buttery', 'buy', 'by', 'bye', 'c', 'ca', 'cairo', 'cake', 'calendar', 'calgary', 'caliber', 'california', 'call', 'called', 'calling', 'calm', 'came', 'camera', 'cammpinnas', 'camp', 'campaigning', 'campeones', 'campinas', 'campinnas', 'can', 'cana', 'canada', 'cancun', 'candid', 'candy', 'canoas', 'canopy', 'cant', 'canyon', 'cap', 'capacity', 'capisci', 'cappin', 'caprica', 'capture', 'car', 'card', 'care', 'career', 'careful', 'carefully', 'carnaval', 'carolina', 'carried', 'carry', 'carrying', 'casa', 'case', 'cash', 'casino', 'castle', 'cat', 'catch', 'category', 'catering', 'cathedral', 'caught', 'cause', 'cautious', 'cave', 'cavern', 'cba', 'celeb', 'celebrate', 'celebrity', 'celestial', 'cencun', 'cent', 'center', 'centrally', 'century', 'cereal', 'certain', 'certainly', 'chain', 'chance', 'change', 'changeable', 'changed', 'changing', 'chaperone', 'charge', 'charged', 'charismatic', 'charming', 'chasing', 'chat', 'chateau', 'cheap', 'cheaper', 'cheapest', 'cheapskate', 'check', 'checked', 'checking', 'cheer', 'chef', 'cherished', 'chic', 'chicago', 'chief', 'chihuahua', 'child', 'chill', 'chit', 'choice', 'choose', 'chooser', 'choosing', 'chose', 'christ', 'circus', 'citizen', 'city', 'ciudad', 'clarified', 'clas', 'class', 'classic', 'classy', 'clean', 'clear', 'clearer', 'clearly', 'cleveland', 'client', 'cloak', 'close', 'closeby', 'closer', 'closest', 'closing', 'club', 'co', 'coast', 'cockroach', 'codey', 'coin', 'coincide', 'cold', 'colder', 'colleague', 'colleauge', 'college', 'colorado', 'columbia', 'columbo', 'columbus', 'comapre', 'combo', 'come', 'comfort', 'coming', 'command', 'commercial', 'commitment', 'community', 'companion', 'company', 'comparable', 'compare', 'compared', 'comparing', 'comparison', 'compatible', 'competition', 'competitor', 'complain', 'complaint', 'complete', 'completed', 'completely', 'complimentary', 'comply', 'comprehend', 'comprende', 'comprises', 'computer', 'concern', 'concerned', 'concerning', 'concert', 'concierge', 'condition', 'conduct', 'confession', 'confidence', 'confidential', 'confidentiality', 'confined', 'confirm', 'confirmation', 'confirmed', 'confirming', 'conflict', 'confused', 'confusing', 'congested', 'congrats', 'congratulation', 'connected', 'connecting', 'connection', 'consequence', 'consider', 'considerably', 'consideration', 'considering', 'consistent', 'consists', 'constraint', 'contact', 'contain', 'continent', 'continental', 'continue', 'contract', 'contraint', 'contrast', 'convenient', 'conveniently', 'convention', 'convince', 'convinced', 'cook', 'cookie', 'cookin', 'cooking', 'cool', 'cooler', 'coolio', 'cooped', 'copy', 'cord', 'cordoba', 'core', 'corner', 'corporation', 'correct', 'correctly', 'correctomundo', 'corrrect', 'corsucant', 'coruscant', 'cosmos', 'cost', 'costing', 'costly', 'cottage', 'couch', 'could', 'couldn', 'count', 'country', 'countryside', 'couple', 'course', 'court', 'courtyard', 'cousin', 'cousing', 'cover', 'covered', 'covert', 'coworker', 'coworkers', 'coz', 'crap', 'crappy', 'crash', 'craving', 'crazy', 'creating', 'creek', 'crew', 'crime', 'crimson', 'criterion', 'croissant', 'cross', 'crowd', 'crown', 'crucial', 'cruel', 'crusty', 'cruz', 'cry', 'cuba', 'cubicle', 'culturally', 'cun', 'cup', 'curiosity', 'curious', 'curitiba', 'current', 'currently', 'curritiba', 'cushion', 'customer', 'cut', 'cute', 'cutting', 'cuz', 'd', 'da', 'dad', 'daddy', 'daily', 'dallas', 'dalle', 'damage', 'dammit', 'damn', 'damned', 'dandy', 'dang', 'dangerous', 'dank', 'darling', 'darn', 'data', 'database', 'date', 'daughter', 'dawg', 'day', 'daydreamer', 'daydreaming', 'days', 'de', 'dead', 'deadline', 'deal', 'dealing', 'dealt', 'dear', 'dearly', 'death', 'debate', 'decadence', 'decent', 'decently', 'decide', 'decided', 'decides', 'deciding', 'decision', 'deeply', 'deets', 'define', 'definite', 'definitely', 'defs', 'deinintely', 'del', 'deliciousness', 'delightful', 'delux', 'deluxe', 'demi', 'demographic', 'den', 'denver', 'deny', 'deparate', 'deparing', 'depart', 'departed', 'departing', 'departs', 'departure', 'depend', 'depending', 'depends', 'deplorable', 'derrick', 'describe', 'described', 'description', 'desert', 'deserve', 'deserves', 'design', 'designer', 'desination', 'desire', 'desired', 'desk', 'desperate', 'despite', 'destinatio', 'destination', 'destined', 'destiny', 'detail', 'detailed', 'determine', 'determined', 'detinations', 'detoit', 'detroit', 'detrut', 'devastating', 'device', 'dfferent', 'diagon', 'dice', 'did', 'didn', 'didnt', 'die', 'diego', 'difference', 'different', 'differing', 'difficult', 'dig', 'dilemma', 'dime', 'dine', 'dip', 'dire', 'direct', 'direction', 'directly', 'dirt', 'dirty', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'discount', 'discover', 'discus', 'discussed', 'discussing', 'discussion', 'disgrace', 'disgusting', 'disney', 'disneyland', 'disobedient', 'distance', 'district', 'ditch', 'diva', 'dive', 'divorce', 'divorced', 'do', 'doable', 'doe', 'doesn', 'doesnt', 'dog', 'doing', 'doke', 'dolaritos', 'dollar', 'domestic', 'domestically', 'domesticate', 'domingo', 'dominican', 'don', 'donated', 'done', 'dont', 'donut', 'dood', 'dope', 'double', 'doubled', 'dough', 'down', 'downgrade', 'downright', 'downtown', 'doyou', 'dozen', 'dragging', 'drama', 'drat', 'draw', 'dreadful', 'dream', 'dreamed', 'dreamer', 'dreamin', 'dreaming', 'drink', 'drive', 'driving', 'drizzle', 'drop', 'dropoff', 'dual', 'dublin', 'duchesse', 'duck', 'dude', 'due', 'duh', 'dull', 'dump', 'dunno', 'duration', 'during', 'duty', 'duuuude', 'dwarf', 'dying', 'e', 'each', 'ear', 'earlier', 'earliest', 'early', 'earned', 'earth', 'easier', 'easiest', 'easily', 'easy', 'eat', 'eats', 'eavailabilities', 'ebony', 'echo', 'economical', 'economy', 'edge', 'eeeeeeeeeeee', 'efficient', 'efficiently', 'egg', 'eh', 'ehat', 'ehhhh', 'eight', 'eighteenth', 'eighth', 'eisley', 'either', 'el', 'elaborate', 'elder', 'elephant', 'eleven', 'eleventh', 'elite', 'else', 'elsewhere', 'elton', 'em', 'email', 'emailed', 'embarrassing', 'emerald', 'emergency', 'employment', 'empty', 'en', 'enclave', 'encounter', 'end', 'endeavour', 'ending', 'energy', 'engine', 'enginge', 'england', 'english', 'enjoy', 'enjoyed', 'enjoys', 'enlightenment', 'enough', 'ensure', 'enter', 'enters', 'entertain', 'entertaining', 'entertainment', 'enthused', 'entice', 'enticing', 'entire', 'entirely', 'envisioning', 'equally', 'equipped', 'equivalent', 'er', 'eric', 'error', 'escape', 'escaping', 'espanol', 'especially', 'essen', 'essence', 'establishment', 'estate', 'esteemed', 'estimate', 'estimated', 'estrella', 'etc', 'europe', 'european', 'eveeeer', 'even', 'evening', 'ever', 'everland', 'every', 'everybody', 'everyday', 'everyone', 'everyones', 'everything', 'everywhere', 'evidently', 'ew', 'eww', 'exact', 'exactly', 'exalted', 'exam', 'example', 'excalibur', 'exceed', 'exceeded', 'excellent', 'except', 'exceptional', 'exchange', 'excited', 'excitement', 'exciting', 'exclusive', 'excursion', 'excuse', 'execute', 'exhausted', 'exist', 'exorbitantly', 'exotic', 'expand', 'expat', 'expect', 'expectation', 'expected', 'expecting', 'expense', 'expensive', 'experience', 'expesnive', 'explain', 'explore', 'exploring', 'exposed', 'exquisite', 'extend', 'extended', 'extends', 'extra', 'extraordinaire', 'extravagant', 'extremely', 'extrodinary', 'eye', 'eyeing', 'f', 'fabled', 'fabulous', 'face', 'facility', 'fact', 'factor', 'failed', 'failing', 'fails', 'fair', 'fairly', 'fairyland', 'fall', 'fam', 'fame', 'family', 'famous', 'fan', 'fancier', 'fanciest', 'fancy', 'fantastic', 'fantasy', 'far', 'fare', 'fashion', 'fast', 'faster', 'fat', 'father', 'fault', 'favorable', 'favorite', 'favour', 'fear', 'feasible', 'feature', 'featured', 'featuring', 'fed', 'feed', 'feel', 'feeling', 'felicidad', 'felicity', 'fella', 'fellow', 'female', 'fernando', 'fetch', 'few', 'fi', 'fiance', 'fictional', 'fifteen', 'fifth', 'fight', 'figure', 'figured', 'file', 'fill', 'film', 'final', 'finalize', 'finalized', 'finally', 'financial', 'financially', 'find', 'finding', 'fine', 'finish', 'finished', 'fire', 'first', 'firstly', 'fish', 'fishing', 'fit', 'fitting', 'five', 'fix', 'fixed', 'flabbergasted', 'flagship', 'flare', 'flashy', 'flaunt', 'flavourtown', 'flee', 'flew', 'flexibility', 'flexibl', 'flexible', 'flgith', 'flight', 'fligths', 'flip', 'floor', 'flop', 'flores', 'florida', 'flushed', 'fly', 'flying', 'fo', 'focus', 'focused', 'fof', 'fog', 'folk', 'follow', 'followed', 'following', 'food', 'foodie', 'fool', 'for', 'fore', 'foreign', 'forget', 'forgot', 'forked', 'form', 'former', 'fort', 'fortaleza', 'fortunate', 'fortunately', 'fortune', 'forward', 'found', 'four', 'fourteen', 'fourth', 'frame', 'fran', 'france', 'francisco', 'frankfurt', 'frat', 'fre', 'freakin', 'free', 'freebie', 'freinds', 'french', 'frequently', 'freshly', 'fri', 'friday', 'friend', 'friendly', 'frig', 'frightening', 'frmom', 'fro', 'from', 'frometh', 'frommmmm', 'front', 'frowning', 'fruition', 'frustrating', 'fukuoka', 'fulfill', 'full', 'fun', 'fund', 'further', 'furthermore', 'future', 'fyi', 'gaggle', 'gal', 'galaxy', 'game', 'gang', 'garden', 'garnered', 'gary', 'gathered', 'gathering', 'gaudalajara', 'gave', 'geez', 'gem', 'general', 'generic', 'gentle', 'germany', 'get', 'getaway', 'getting', 'gift', 'gig', 'gigantic', 'gim', 'girl', 'girlfriend', 'girlie', 'girlz', 'give', 'given', 'giving', 'glacier', 'glad', 'glee', 'glitch', 'global', 'globe', 'globetrotter', 'globetrotting', 'glorious', 'glowing', 'go', 'goal', 'god', 'godforsaken', 'godric', 'goian', 'goiania', 'goin', 'goinania', 'going', 'goinggg', 'gold', 'golden', 'golf', 'gomez', 'gon', 'gona', 'gone', 'good', 'goodbye', 'goodness', 'google', 'googling', 'goooo', 'gooood', 'gorge', 'gorgeous', 'gosh', 'got', 'gotcha', 'gotham', 'gots', 'gourmet', 'gq', 'grab', 'grace', 'graced', 'gracias', 'grade', 'graduated', 'graffiti', 'grand', 'grandchild', 'grandfather', 'grandiose', 'grandkids', 'grandma', 'grandmother', 'grandson', 'grant', 'granted', 'great', 'greatest', 'greece', 'greedy', 'green', 'greeting', 'greg', 'grey', 'grimacing', 'grinning', 'gross', 'ground', 'group', 'groupie', 'grown', 'grownup', 'grrrrrrrrr', 'gt', 'guadala', 'guadalajara', 'guard', 'guarding', 'guess', 'guessing', 'guest', 'guesting', 'guide', 'guideline', 'gun', 'gurl', 'gurls', 'guru', 'guy', 'gym', 'h', 'ha', 'haaaaaaaaayyyy', 'haayyyyy', 'had', 'hadn', 'haev', 'hagrid', 'haha', 'hahah', 'hahahahahahahahah', 'hail', 'hailing', 'hair', 'haircut', 'half', 'hallelujah', 'hamburg', 'hambuurg', 'hand', 'handle', 'handled', 'handy', 'hang', 'happen', 'happened', 'happening', 'happens', 'happiest', 'happin', 'happy', 'harbor', 'harborview', 'hard', 'harder', 'hardly', 'harold', 'harry', 'hassle', 'hasty', 'hate', 'hater', 'hauston', 'have', 'haven', 'havent', 'having', 'hay', 'haystack', 'hayyyy', 'he', 'head', 'headed', 'heading', 'headspace', 'hear', 'heard', 'hearing', 'heart', 'heat', 'heaven', 'heck', 'helicopter', 'hell', 'hellion', 'helllllo', 'hellllo', 'helllloooo', 'helllo', 'hello', 'hellooooo', 'helo', 'help', 'helped', 'helpful', 'helping', 'henry', 'her', 'here', 'hesitate', 'hey', 'heya', 'heyaaa', 'heyo', 'heyooooo', 'heyy', 'heyyy', 'heyyyy', 'heyyyyy', 'hi', 'hiding', 'high', 'higher', 'highest', 'highly', 'hiiii', 'hiiiii', 'hill', 'hilton', 'him', 'hip', 'hippest', 'hipster', 'hiroshami', 'hiroshima', 'hiroshma', 'his', 'historic', 'historical', 'historically', 'history', 'hit', 'hitchin', 'hitting', 'hiya', 'hm', 'hmm', 'hmmm', 'hmmmm', 'hmmmmm', 'hmph', 'ho', 'hogsmead', 'hogsmeade', 'hola', 'hold', 'holding', 'hole', 'holiday', 'hollow', 'holy', 'home', 'homebody', 'homegirl', 'homeslice', 'hometown', 'homies', 'honest', 'honestly', 'honey', 'honeymoon', 'honeymooner', 'honeymooning', 'honour', 'hook', 'hop', 'hope', 'hopefully', 'hoping', 'horizon', 'horizonte', 'horrible', 'hospital', 'host', 'hostel', 'hot', 'hotel', 'hotle', 'hotles', 'hotspot', 'hottest', 'hour', 'house', 'houst', 'houston', 'how', 'howdy', 'however', 'howmuch', 'hows', 'hubby', 'huge', 'hugging', 'hugo', 'huh', 'human', 'humanly', 'humble', 'hundo', 'hundred', 'hung', 'hungry', 'hunt', 'hunter', 'hunting', 'hurry', 'hurt', 'husband', 'hustle', 'huzzah', 'hyped', 'hypothetical', 'hypothetically', 'hyrule', 'i', 'ia', 'ian', 'iceberg', 'id', 'idea', 'ideal', 'ideally', 'idiot', 'idk', 'if', 'iffy', 'ill', 'illinois', 'illustrious', 'im', 'imaginary', 'imagination', 'imagine', 'imagined', 'imagining', 'imm', 'imma', 'immediately', 'immense', 'impeccable', 'importance', 'important', 'importantly', 'impress', 'impressed', 'impression', 'impressive', 'improvement', 'impulsive', 'in', 'inbox', 'inca', 'inclined', 'include', 'included', 'includes', 'including', 'inclusive', 'inconvenience', 'increase', 'increased', 'increasing', 'incredible', 'incredibly', 'indecisive', 'indeed', 'indeeed', 'independent', 'independently', 'indiana', 'indianapolis', 'indicate', 'indication', 'indoor', 'indulge', 'indulging', 'ine', 'inetrested', 'infant', 'inflexible', 'info', 'inform', 'information', 'informed', 'inherited', 'ini', 'inimitable', 'initial', 'inn', 'input', 'inquire', 'inquiring', 'insane', 'inside', 'inspection', 'inspiration', 'instagram', 'instead', 'institution', 'insulted', 'insulting', 'insurance', 'intend', 'intended', 'interest', 'interested', 'interesting', 'intern', 'international', 'internet', 'internship', 'intership', 'intersted', 'interview', 'inthe', 'into', 'intouch', 'intoxication', 'intrigued', 'intriguing', 'investment', 'investor', 'invoice', 'involved', 'involves', 'involving', 'ironically', 'irrelevant', 'is', 'island', 'isle', 'isn', 'isnt', 'isntead', 'issue', 'it', 'italy', 'itinerary', 'itll', 'itself', 'ittt', 'itty', 'ive', 'ivory', 'iw', 'iwll', 'jackpot', 'jade', 'jam', 'jamaica', 'janeiro', 'janeiror', 'japan', 'jaunt', 'jeeeez', 'jeez', 'jennifer', 'jersusalem', 'jerusalem', 'jesus', 'jet', 'jewel', 'jimmy', 'job', 'joe', 'john', 'johnny', 'join', 'joining', 'joint', 'joke', 'jonny', 'jose', 'journey', 'joy', 'joyful', 'jsut', 'juan', 'juarez', 'juicy', 'juliette', 'jump', 'june', 'jungle', 'just', 'justin', 'k', 'kabul', 'kakariko', 'kardashians', 'katniss', 'keen', 'keep', 'keeping', 'key', 'kid', 'kiddin', 'kidding', 'kiddy', 'kidney', 'kiji', 'kill', 'killin', 'killing', 'kind', 'kinda', 'kindergarten', 'kindly', 'king', 'kingston', 'kioto', 'kirei', 'kk', 'knew', 'know', 'knowing', 'known', 'kobe', 'kocchi', 'kochi', 'korea', 'kyoto', 'la', 'lad', 'lady', 'lame', 'land', 'landing', 'landmark', 'landscape', 'lap', 'large', 'lassie', 'last', 'lasting', 'lastly', 'late', 'lately', 'later', 'latest', 'latter', 'lauderdale', 'lauderdle', 'lavish', 'lavished', 'lavishly', 'law', 'lawls', 'lawrence', 'lawyer', 'lay', 'lbe', 'le', 'lead', 'leading', 'leaf', 'leaning', 'learn', 'learning', 'least', 'leave', 'leaving', 'left', 'leftover', 'leg', 'legacy', 'legendary', 'legion', 'legit', 'leisure', 'lend', 'length', 'lennon', 'lens', 'leon', 'lesser', 'lesson', 'let', 'letdown', 'lethargy', 'letting', 'level', 'liberty', 'lie', 'liekly', 'life', 'lifesaver', 'lifetime', 'lifted', 'light', 'like', 'liked', 'likely', 'liking', 'lil', 'lima', 'limit', 'limitation', 'limited', 'limiting', 'line', 'link', 'list', 'listed', 'listen', 'listing', 'lit', 'literally', 'litle', 'little', 'live', 'lived', 'living', 'lke', 'll', 'llama', 'lmao', 'lme', 'load', 'loan', 'loathing', 'lobster', 'local', 'locate', 'located', 'location', 'loch', 'lock', 'lodge', 'lodging', 'logical', 'loius', 'lol', 'london', 'lone', 'lonely', 'lonesome', 'long', 'longer', 'longest', 'look', 'looked', 'lookin', 'looking', 'loony', 'loose', 'lorraine', 'los', 'lose', 'lost', 'lot', 'lotta', 'lottery', 'louis', 'love', 'lovebird', 'loved', 'lovely', 'lover', 'loveys', 'low', 'lower', 'lowest', 'lowkey', 'lowlife', 'lt', 'luck', 'lucked', 'lucky', 'lunar', 'lunch', 'lure', 'lush', 'luxe', 'luxuiours', 'luxurious', 'luxury', 'm', 'm8', 'ma', 'maceia', 'maceio', 'machine', 'mad', 'madam', 'made', 'madly', 'madonna', 'madrid', 'magazine', 'magic', 'magical', 'magnificent', 'mah', 'maid', 'main', 'mainaus', 'mainly', 'majestic', 'majesty', 'major', 'majority', 'make', 'making', 'mall', 'mama', 'man', 'manage', 'managed', 'manager', 'manas', 'manaus', 'mannheim', 'mannnn', 'manor', 'mansion', 'mantle', 'many', 'maple', 'mar', 'march', 'marginally', 'marina', 'marked', 'market', 'marriage', 'married', 'marrying', 'marseille', 'martha', 'marvel', 'marvellous', 'mask', 'massachusetts', 'massively', 'masterpiece', 'mastiff', 'match', 'matching', 'math', 'matrimony', 'matter', 'max', 'maximum', 'may', 'maybe', 'mcgriddles', 'me', 'meal', 'mean', 'meaning', 'meant', 'meantime', 'meat', 'meet', 'meeting', 'mega', 'meh', 'melbourne', 'mellow', 'melting', 'member', 'memorable', 'men', 'mental', 'mention', 'mentioned', 'merci', 'mere', 'merrymaking', 'mess', 'message', 'messing', 'meticulous', 'mewtwo', 'mexica', 'mexican', 'mexico', 'mexicoh', 'miami', 'middle', 'midnight', 'might', 'milan', 'mildly', 'miller', 'million', 'mind', 'minded', 'mine', 'mini', 'minimum', 'minneapolis', 'minnesota', 'minor', 'minute', 'mirror', 'miserable', 'misread', 'miss', 'missing', 'mission', 'mistake', 'mistress', 'mistyped', 'misunderstanding', 'misunderstood', 'mixed', 'mmm', 'mmmm', 'mo', 'modest', 'moi', 'moly', 'mom', 'moment', 'mommy', 'mon', 'monday', 'monetary', 'money', 'monterrey', 'month', 'montreal', 'moolah', 'moon', 'more', 'morning', 'mortgage', 'most', 'motel', 'mother', 'mountain', 'mouth', 'move', 'moved', 'movie', 'moving', 'mr', 'mtl', 'muahahah', 'much', 'multi', 'multinational', 'multiple', 'multiply', 'mum', 'munchkins', 'mundo', 'munich', 'murdered', 'muse', 'museum', 'must', 'my', 'myself', 'mythical', 'n', 'na', 'nabbit', 'naggy', 'nagoya', 'nah', 'nahhh', 'name', 'named', 'namely', 'naples', 'narrow', 'naw', 'near', 'nearby', 'nearest', 'neat', 'necessarily', 'necessary', 'necessity', 'need', 'needed', 'needle', 'neglected', 'negotiable', 'negotiate', 'neighbour', 'neighbourhood', 'neither', 'neon', 'nepal', 'nephew', 'nervous', 'nest', 'never', 'neverland', 'nevermind', 'new', 'newfound', 'newlywed', 'nework', 'news', 'next', 'nice', 'nicely', 'nicer', 'nicest', 'night', 'nightlife', 'nightmare', 'nine', 'nineteen', 'ninth', 'nitpicky', 'no', 'noble', 'nobody', 'noisy', 'non', 'none', 'nonoppe', 'nooo', 'noooo', 'nooooo', 'noooooo', 'nope', 'nopeee', 'nor', 'normal', 'north', 'not', 'notable', 'note', 'noted', 'nothing', 'notice', 'noticeably', 'notification', 'notify', 'nova', 'novel', 'now', 'nowhere', 'nugget', 'number', 'numerous', 'nut', 'ny', 'nyc', 'o', 'object', 'obligation', 'oblige', 'obliged', 'obsidian', 'obvious', 'obviously', 'ocean', 'oceanside', 'oclock', 'oct', 'oct4', 'october', 'odd', 'of', 'off', 'offer', 'offered', 'offering', 'office', 'officer', 'official', 'officially', 'offspring', 'often', 'oh', 'ohh', 'ohhh', 'ohhhhh', 'oishi', 'ok', 'okaaaay', 'okay', 'okie', 'okwhat', 'old', 'ole', 'olive', 'om', 'omg', 'on', 'once', 'one', 'online', 'only', 'onsite', 'ontario', 'onto', 'onyx', 'oo', 'oof', 'ooh', 'ook', 'oooo', 'ooooo', 'oooooo', 'ooooooo', 'oops', 'open', 'opened', 'opening', 'operate', 'operating', 'operation', 'opportunity', 'opposed', 'opt', 'opted', 'optimistic', 'option', 'or', 'orb', 'order', 'oriental', 'origin', 'original', 'orlando', 'ornate', 'oro', 'osaka', 'ot', 'other', 'others', 'otherwise', 'otrefer', 'ouch', 'ouf', 'ought', 'oughta', 'oui', 'our', 'ourselves', 'out', 'outdoor', 'outgoing', 'outing', 'outside', 'outstanding', 'outta', 'over', 'overcalculated', 'overload', 'overlooked', 'overrun', 'overseas', 'own', 'oy', 'oyster', 'p', 'pacific', 'pack', 'packag', 'package', 'packaged', 'packaging', 'packing', 'paid', 'pain', 'paint', 'pajama', 'pal', 'palace', 'palacio', 'pallet', 'palm', 'paltry', 'pampered', 'pampering', 'pan', 'panic', 'pap', 'paparazzo', 'paper', 'par', 'paradise', 'parakeet', 'parallel', 'parameter', 'parent', 'parental', 'paris', 'park', 'parkig', 'parking', 'parole', 'part', 'particular', 'particularly', 'partiers', 'partner', 'partnership', 'party', 'partying', 'pas', 'passed', 'passenger', 'passport', 'past', 'pastry', 'pasture', 'path', 'pathetic', 'patience', 'patronage', 'paulo', 'pause', 'pay', 'paying', 'payment', 'paz', 'peace', 'peak', 'peasanty', 'peek', 'peeping', 'pen', 'pennsylvania', 'penny', 'penpal', 'people', 'per', 'perf', 'perfecci', 'perfect', 'perfection', 'perfectly', 'perform', 'performing', 'perhaps', 'period', 'perk', 'permanently', 'permission', 'permit', 'perrier', 'persevere', 'person', 'perspective', 'pertinent', 'pet', 'peter', 'peterburg', 'petersburg', 'pflying', 'phenomenal', 'philadelphia', 'phili', 'philly', 'pho', 'phoenix', 'phone', 'photo', 'photograph', 'photographer', 'photography', 'physically', 'pic', 'pick', 'pickle', 'pickup', 'picky', 'picture', 'picturesque', 'piggybank', 'pikachu', 'pilgrimage', 'pinch', 'pinching', 'pink', 'pinnacle', 'pique', 'pit', 'pittsborgh', 'pittsburgh', 'place', 'placed', 'placing', 'plan', 'plane', 'planet', 'planned', 'planning', 'plastered', 'play', 'playground', 'plaza', 'pleasant', 'pleasantly', 'please', 'pleased', 'pleaseeee', 'pleasure', 'plenty', 'pls', 'plus', 'plz', 'pm', 'pocket', 'point', 'pok', 'pokemon', 'pokestops', 'pole', 'police', 'polite', 'polygamist', 'ponder', 'pondering', 'poo', 'pool', 'poor', 'pop', 'poppin', 'popping', 'popstar', 'popular', 'pork', 'portland', 'porto', 'poshest', 'position', 'positively', 'posse', 'possibility', 'possible', 'possibly', 'post', 'potential', 'potentially', 'potter', 'pound', 'poz', 'ppl', 'practice', 'prairie', 'praised', 'pray', 'praytell', 'precise', 'predicated', 'prefer', 'preferable', 'preferably', 'preference', 'preferred', 'pregnant', 'premise', 'prepare', 'prepared', 'preposterous', 'prerogative', 'present', 'presented', 'presenting', 'presently', 'prestigious', 'pretend', 'pretttttty', 'pretty', 'previous', 'previously', 'price', 'priced', 'pricey', 'priciest', 'pricing', 'primavera', 'princess', 'priority', 'prism', 'pristine', 'private', 'privileged', 'prob', 'probably', 'problem', 'proceed', 'process', 'processed', 'processing', 'product', 'profile', 'program', 'programmed', 'programy', 'project', 'prole', 'promise', 'promised', 'promising', 'pronto', 'proper', 'property', 'prophecy', 'provide', 'provided', 'provides', 'provision', 'proximity', 'psssstttttt', 'psychotic', 'pub', 'public', 'puebla', 'pueblla', 'pull', 'pun', 'punta', 'punto', 'puppers', 'purchase', 'purchased', 'purchasing', 'purpose', 'push', 'put', 'putting', 'quality', 'quarter', 'queen', 'queenstown', 'query', 'question', 'quick', 'quickly', 'quiet', 'quite', 'quote', 'quoted', 'r', 'radar', 'raff', 'raid', 'rain', 'rainy', 'raise', 'raised', 'rally', 'ran', 'range', 'ranging', 'rank', 'ranking', 'ranting', 'rap', 'rare', 'rarely', 'rat', 'rate', 'rated', 'rather', 'rating', 'ravel', 'raven', 'raving', 're', 'reach', 'read', 'ready', 'real', 'reality', 'realize', 'realized', 'reallllly', 'really', 'reason', 'reasonable', 'reasonably', 'receive', 'received', 'receiving', 'recent', 'recently', 'reception', 'recife', 'recipe', 'reckon', 'recofe', 'recommend', 'recommendation', 'reconsider', 'record', 'recover', 'recreation', 'recreational', 'red', 'reduce', 'reduced', 'redwood', 'reel', 'refer', 'refined', 'refreshing', 'refuse', 'regal', 'regard', 'regarding', 'regardless', 'registered', 'regret', 'regretfully', 'regrettably', 'regroup', 'regular', 'reimburse', 'reina', 'reiterate', 'reject', 'relative', 'relax', 'relaxation', 'relaxed', 'relaxing', 'relief', 'relieved', 'remain', 'remember', 'remembered', 'remind', 'reminding', 'remote', 'renaissance', 'renowned', 'rent', 'rental', 'renting', 'repeat', 'repercussion', 'report', 'represent', 'republic', 'reputable', 'request', 'requested', 'require', 'required', 'requirement', 'requires', 'research', 'researching', 'reservation', 'reserve', 'reserved', 'reside', 'residence', 'resife', 'resort', 'respect', 'respectable', 'respective', 'respectively', 'response', 'responsibility', 'rest', 'restaurant', 'rested', 'restraint', 'restriction', 'result', 'resurrect', 'rethink', 'retirement', 'retreat', 'retro', 'retund', 'retunr', 'return', 'returned', 'returnign', 'returning', 'reunion', 'reveals', 'review', 'reviewed', 'revised', 'reward', 'rewarded', 'rgiht', 'ribbon', 'ribero', 'rich', 'richard', 'rickon', 'rid', 'riddance', 'ride', 'ridge', 'ridiculous', 'riff', 'right', 'rio', 'rip', 'risk', 'risky', 'ritziest', 'rival', 'river', 'riverside', 'rme', 'rn', 'road', 'rob', 'robb', 'robin', 'robot', 'roll', 'rolling', 'roman', 'romantic', 'rome', 'ron', 'room', 'rosario', 'rose', 'roster', 'rough', 'round', 'rounded', 'route', 'routine', 'royal', 'royalty', 'rpocessed', 'rub', 'rude', 'rug', 'ruin', 'rumour', 'run', 'rung', 'running', 'rush', 'rushing', 'rustic', 's', 'sacramento', 'sacre', 'sad', 'sadder', 'sadly', 'safari', 'safe', 'safer', 'sage', 'said', 'sake', 'sakura', 'sale', 'salt', 'salut', 'salvador', 'same', 'san', 'sanantososos', 'sanctuary', 'sanf', 'sansa', 'sansot', 'santa', 'santiago', 'santios', 'santo', 'santodomingo', 'santos', 'santso', 'sanuary', 'sao', 'sapphire', 'sapporo', 'sat', 'satisfaction', 'satisfactory', 'satisfied', 'satisfy', 'saturday', 'saunter', 'savage', 'save', 'saved', 'saving', 'saw', 'saweeeet', 'say', 'sayin', 'saying', 'sayonara', 'sbook', 'scan', 'scare', 'scarlet', 'scenario', 'scene', 'scenery', 'scenic', 'schedule', 'schmooze', 'schmoozing', 'school', 'scope', 'score', 'scratch', 'screw', 'scrounge', 'se', 'seafood', 'search', 'searched', 'searching', 'seaside', 'season', 'seat', 'seating', 'seattle', 'sec', 'second', 'secondary', 'secondly', 'secret', 'secretary', 'secure', 'secured', 'see', 'seedy', 'seeing', 'seek', 'seeking', 'seem', 'seemed', 'seems', 'seen', 'seize', 'select', 'selected', 'selection', 'selena', 'self', 'sell', 'semi', 'senbai', 'send', 'sendai', 'sending', 'sense', 'sensitive', 'sensory', 'sent', 'seoul', 'sep', 'sepember', 'sepetember', 'sepnd', 'sept', 'sept12', 'septeber', 'september', 'september2nd', 'septembr', 'septembre', 'septemeber', 'septemer', 'septmeber', 'serene', 'serf', 'serious', 'seriously', 'serve', 'served', 'service', 'serviced', 'serving', 'sesh', 'session', 'set', 'setting', 'settle', 'settled', 'seven', 'seventeenth', 'seventh', 'several', 'severall', 'sevice', 'sf', 'shabby', 'shack', 'shall', 'shame', 'shamed', 'share', 'shark', 'sharp', 'sharpei', 'she', 'shebang', 'shes', 'shield', 'ship', 'shit', 'sho', 'shocking', 'shoot', 'shop', 'shoppin', 'shopping', 'short', 'shortened', 'shortening', 'shorter', 'shortest', 'shortly', 'shot', 'should', 'shoulder', 'shouldmention', 'shouldn', 'shouldve', 'show', 'showed', 'showered', 'showing', 'shuck', 'sick', 'side', 'sidence', 'sierra', 'sight', 'sign', 'signed', 'significant', 'significantly', 'signing', 'silly', 'silver', 'similar', 'similarly', 'simple', 'simply', 'since', 'sir', 'sire', 'siren', 'sister', 'site', 'sits', 'sitting', 'situated', 'situation', 'six', 'sixteenth', 'sixth', 'size', 'skedaddle', 'skeedaddle', 'sketch', 'sketched', 'sketchy', 'ski', 'skin', 'skip', 'sky', 'sl', 'slack', 'sleep', 'sleeping', 'sleepy', 'slider', 'slight', 'slightly', 'slot', 'slow', 'small', 'smart', 'smaug', 'smile', 'smiley', 'smiling', 'smith', 'smitten', 'snap', 'snapped', 'snazzy', 'snooze', 'snowy', 'sny', 'so', 'socializing', 'society', 'soft', 'solar', 'sold', 'solid', 'solitude', 'solo', 'som', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'son', 'soon', 'sooner', 'soonest', 'sooo', 'soooo', 'sooooo', 'soooooo', 'sooooooooo', 'sophomore', 'sorry', 'sort', 'sorta', 'soul', 'sound', 'sounding', 'source', 'south', 'southern', 'souvenir', 'spa', 'space', 'spain', 'span', 'spare', 'spared', 'spark', 'sparkling', 'speak', 'special', 'specialize', 'specially', 'specific', 'specifically', 'specification', 'specify', 'spectacular', 'spell', 'spend', 'spender', 'spending', 'spent', 'spetmebr', 'spicing', 'spire', 'splendid', 'splurge', 'splurged', 'splurging', 'spoil', 'spoiled', 'spoiling', 'spoke', 'sport', 'sportsteam', 'spot', 'spotted', 'spotting', 'spouse', 'spread', 'spreading', 'spree', 'spriiiiing', 'spriinggg', 'spring', 'spt', 'squad', 'square', 'squeeze', 'st', 'stacked', 'staff', 'stake', 'stalker', 'stalking', 'stand', 'standard', 'standing', 'star', 'stardust', 'starhotel', 'starlight', 'start', 'starting', 'startup', 'stashed', 'stat', 'state', 'stated', 'statement', 'stating', 'stationed', 'stature', 'stay', 'staycation', 'stayed', 'staying', 'stayong', 'steal', 'stellar', 'step', 'stephen', 'sterling', 'stick', 'still', 'stimulating', 'stinkin', 'stockholm', 'stoked', 'stop', 'stopping', 'store', 'straight', 'straighten', 'strange', 'stranger', 'strapping', 'street', 'stretch', 'strict', 'strictly', 'stride', 'stright', 'strike', 'stroll', 'stronger', 'struggling', 'stuck', 'stud', 'student', 'study', 'studying', 'stuff', 'stupendous', 'stupid', 'stutter', 'stuttgart', 'style', 'subject', 'sublime', 'submit', 'suburb', 'succeeded', 'succesfully', 'success', 'successfully', 'succulent', 'such', 'suck', 'sucking', 'suddenly', 'sue', 'suffering', 'suffice', 'sufficient', 'suggest', 'suggested', 'suggestion', 'sugoi', 'suh', 'suit', 'suitable', 'suite', 'sum', 'summer', 'summit', 'sun', 'sunday', 'sunglass', 'sunny', 'sunrise', 'sunset', 'sunshine', 'suntan', 'sunway', 'sup', 'super', 'superb', 'superstar', 'supply', 'suppose', 'supposed', 'supreme', 'sure', 'surely', 'surfer', 'surprise', 'surprised', 'surrounding', 'surroundings', 'suspect', 'swankiest', 'swanky', 'swarmed', 'swear', 'sweet', 'sweeter', 'sweetie', 'swim', 'swimmingly', 'swing', 'switch', 'sword', 'sydney', 'system', 't', 'ta', 'table', 'tacking', 'tacky', 'taco', 'tag', 'tagging', 'taht', 'tahts', 'take', 'taken', 'takin', 'taking', 'talk', 'talkin', 'talking', 'tampa', 'tan', 'tanya', 'target', 'tarvels', 'task', 'tasked', 'taste', 'tbd', 'tea', 'teach', 'team', 'teammate', 'technology', 'tee', 'teehee', 'tel', 'tell', 'telling', 'temple', 'temporary', 'tempted', 'tempting', 'ten', 'tend', 'tent', 'tenth', 'term', 'termina', 'terrible', 'terribly', 'terrific', 'th', 'than', 'thang', 'thank', 'thanks', 'thanx', 'that', 'thatll', 'thats', 'thave', 'the', 'the25th', 'theater', 'theatre', 'theed', 'their', 'them', 'then', 'theoretically', 'theory', 'ther', 'there', 'thereafter', 'therefore', 'these', 'they', 'thing', 'think', 'thinking', 'third', 'thirdly', 'thirteenth', 'thirtieth', 'this', 'tho', 'thorough', 'thoroughly', 'those', 'thou', 'though', 'thought', 'thousand', 'three', 'thrifty', 'thrilled', 'thrilling', 'through', 'throughout', 'throw', 'throwing', 'thursday', 'thx', 'tibetan', 'ticket', 'ticketing', 'tight', 'tijuana', 'til', 'till', 'time', 'timeframe', 'timeline', 'tip', 'tired', 'tirp', 'title', 'tix', 'tjiuana', 'to', 'toast', 'toastless', 'today', 'tofino', 'together', 'togo', 'toilet', 'tokyo', 'told', 'toluca', 'tolucca', 'tom', 'tommorow', 'tommy', 'tomorrow', 'ton', 'tone', 'toned', 'tongue', 'tonight', 'too', 'toodles', 'took', 'top', 'topic', 'tormented', 'torn', 'torono', 'toronto', 'tot', 'total', 'totally', 'touch', 'tough', 'tour', 'touring', 'tournament', 'towards', 'tower', 'town', 'tracking', 'trainer', 'tram', 'tranquil', 'tranquila', 'transfer', 'transport', 'trap', 'trash', 'travel', 'travelchat', 'traveled', 'traveler', 'traveling', 'travelled', 'traveller', 'travelling', 'tread', 'treasure', 'treat', 'treated', 'treating', 'trendy', 'tried', 'trip', 'tripadoodle', 'triple', 'trippy', 'triumph', 'tropic', 'tropical', 'trouble', 'truck', 'true', 'truly', 'trump', 'trust', 'try', 'tryina', 'trying', 'tryna', 'tto', 'tub', 'tues', 'tuesday', 'tune', 'turn', 'turned', 'turning', 'tweet', 'twentieth', 'twenty', 'twice', 'twin', 'two', 'twonies', 'type', 'typo', 'u', 'ugh', 'ughhhh', 'ughhhhhhhhhhh', 'uh', 'ulsan', 'um', 'umbrella', 'umm', 'ummm', 'ummmm', 'ummmmm', 'un', 'una', 'unable', 'unaccompanied', 'unamused', 'unavailable', 'unbelievable', 'uncapped', 'uncommon', 'undecided', 'under', 'underneath', 'understand', 'understanding', 'understood', 'unfortunate', 'unfortunately', 'unfortuntely', 'unhelpful', 'uni', 'uniform', 'uniiii', 'united', 'unitl', 'univeristy', 'universe', 'university', 'unless', 'unlike', 'unlimited', 'uno', 'unofrtunately', 'unpaid', 'unpleasant', 'unrated', 'unsatisfactory', 'unsure', 'until', 'untill', 'up', 'upcoming', 'update', 'upfront', 'upgrade', 'upgraded', 'upgrading', 'upon', 'upped', 'ups', 'upscale', 'ur', 'urban', 'urgent', 'usa', 'usage', 'usd', 'use', 'used', 'useless', 'user', 'using', 'usual', 'usually', 'ut', 'utmost', 'uunder', 'uyeah', 'v', 'va', 'vacancy', 'vacation', 'vacationg', 'vacationing', 'vacatoin', 'vacay', 'vagas', 'vale', 'valencia', 'valley', 'value', 'valued', 'van', 'vancouver', 'vanilla', 'varies', 'variety', 'various', 'varying', 've', 'veg', 'vega', 'vegan', 'venerable', 'verification', 'verify', 'veritable', 'vernon', 'version', 'vertex', 'very', 'vi', 'via', 'viable', 'vicinity', 'view', 'viewpoint', 'villa', 'village', 'vineyard', 'viridian', 'visit', 'visiting', 'vitoria', 'void', 'volunteer', 'vortex', 'vous', 'voyage', 'voyaging', 'w', 'wa', 'waffle', 'waht', 'wait', 'waiting', 'walk', 'walking', 'wallet', 'wan', 'wana', 'want', 'wanted', 'wanting', 'warm', 'warmer', 'warrant', 'washington', 'wasn', 'wasnt', 'waste', 'wasting', 'watch', 'watcha', 'water', 'way', 'wayward', 'wayyyyyy', 'we', 'wealth', 'weary', 'weather', 'web', 'website', 'wed', 'wedding', 'wednesday', 'weeeelllll', 'week', 'weekend', 'weenie', 'wehn', 'weigh', 'weird', 'welcome', 'well', 'welll', 'welllll', 'wen', 'went', 'were', 'weren', 'west', 'western', 'wet', 'wha', 'whaaaat', 'whaaat', 'whacked', 'what', 'whatcha', 'whatever', 'whatre', 'whats', 'whatsoever', 'whattttt', 'whcih', 'wheel', 'when', 'whence', 'wheneveer', 'whenever', 'where', 'whereas', 'wherever', 'whether', 'whew', 'which', 'whichever', 'whig', 'while', 'whim', 'whipped', 'whisper', 'white', 'whne', 'who', 'whoa', 'whoever', 'whole', 'whooping', 'whoping', 'whose', 'wht', 'why', 'whyfly', 'wi', 'wide', 'wider', 'wife', 'wifey', 'wifi', 'wih', 'wil', 'wild', 'will', 'willing', 'willow', 'win', 'window', 'windowl', 'wine', 'wink', 'winking', 'winner', 'winning', 'winter', 'wippersnappers', 'wire', 'wireless', 'wise', 'wish', 'wishlist', 'with', 'within', 'withing', 'without', 'witn', 'wizard', 'woah', 'wohoo', 'wolf', 'woman', 'won', 'wonder', 'wonderful', 'wonderfully', 'wondering', 'wonderland', 'wont', 'woo', 'woohoo', 'woooohooooooo', 'wooooohoooooo', 'word', 'work', 'worker', 'working', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'worthy', 'would', 'wouldn', 'wouldnt', 'wow', 'wozbot', 'write', 'writer', 'writing', 'wrong', 'wrote', 'wth', 'wtv', 'wwhen', 'wwhich', 'ya', 'yaaaa', 'yaassss', 'yas', 'yass', 'yassss', 'yasssss', 'yay', 'yea', 'yeaaa', 'yeah', 'yeahhhh', 'yeahhhhhhh', 'year', 'yearly', 'yell', 'yelling', 'yep', 'yeppers', 'yepppppp', 'yes', 'yessir', 'yesterday', 'yet', 'yield', 'yielding', 'yikes', 'yippee', 'yippeeee', 'yo', 'yooooo', 'york', 'yorkie', 'you', 'young', 'youngin', 'youngster', 'your', 'youre', 'yours', 'yourself', 'yous', 'youth', 'youu', 'youuuuuuuuuuu', 'yu', 'yuck', 'yum', 'yup', 'yupp', 'ze', 'zealand', 'zero', 'zion', 'zone']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q-GHFyCG8iMg","colab_type":"code","colab":{}},"source":["# In this cell we are creating our training data. It is basically creating a word vector for each word, and corresponding class vector\n","# initializing training data\n","training = []\n","output_empty = [0] * len(classes)\n","for doc in documents:\n","    # initializing bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","    # lemmatize each word - create base word, in attempt to represent related words\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","    # create our bag of words array with 1, if word match found in current pattern\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    # output is a '0' for each tag and '1' for current tag (for each pattern)\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training.append([bag, output_row])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ahj-fe3i74TQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592492303675,"user_tz":240,"elapsed":7120,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"bdb84cf9-bc42-4f7d-e947-f4fb2e4922c4"},"source":["# shuffle our features and turn into np.array. This appears as though it would make learning a little less biased.\n","random.shuffle(training)\n","training = np.array(training)\n","# create train and test lists. X - patterns, Y - intents\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","print(\"Training data created\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training data created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IFRZoX-274dO","colab_type":"code","colab":{}},"source":["# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n","# equal to number of intents to predict output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9U-72BkM74bc","colab_type":"code","colab":{}},"source":["# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","#fitting and saving the model\n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n","model.save('chatbot_model.h5', hist)\n","\n","print(\"model created\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hTD-Ldru74Z3","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","model = load_model('chatbot_model.h5')\n","import json\n","import random\n","intents = json.loads(open('/content/drive/My Drive/1000ml/Project 7 - Chatbot/Data/frames.json').read())\n","words = pickle.load(open('words.pkl','rb'))\n","classes = pickle.load(open('classes.pkl','rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xNyOKWKT74W3","colab_type":"code","colab":{}},"source":["def clean_up_sentence(sentence):\n","    '''This function takes in a sentence, splits it into words, lemmatizes them and returns the list of words.'''\n","    sentence_words = nltk.word_tokenize(sentence)\n","    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n","    return sentence_words\n","\n","# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n","def bow(sentence, words, show_details=True):\n","    '''This function takes in a sentence, a bunch of words and returns a bag of words for words present in that sentence.'''\n","    # tokenize the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","    # bag of words - matrix of N words, vocabulary matrix\n","    bag = [0]*len(words)\n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s:\n","                # assign 1 if current word is in the vocabulary position\n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","    return(np.array(bag))\n","\n","def predict_class(sentence, model):\n","    '''Based on the previous classes, this function attempts to predict the class of response based on the words in the sentence'''\n","    # filter out predictions below a threshold\n","    p = bow(sentence, words,show_details=False)\n","    res = model.predict(np.array([p]))[0]\n","    ERROR_THRESHOLD = 0.25\n","    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n","    return return_list\n","\n","def getResponse(ints, intents_json):\n","    tag = ints[0]['intent']\n","    list_of_intents = intents_json['intents']\n","    for i in list_of_intents:\n","        if(i['tag']== tag):\n","            result = random.choice(i['responses'])\n","            break\n","    return result\n","\n","def chatbot_response(msg):\n","    ints = predict_class(msg, model)\n","    res = getResponse(ints, intents)\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wJapH1wdV4zu","colab_type":"text"},"source":["# Stuff I dont need right now"]},{"cell_type":"code","metadata":{"id":"W4AZVZYlHqdI","colab_type":"code","colab":{}},"source":["json_df['turns'].iloc[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qb0yJabB_I82","colab_type":"code","colab":{}},"source":["# These are dialogues from a Ubuntu users \n","df1=pd.read_csv('/content/drive/My Drive/1000ml/Project 7 - Chatbot/Data/dialogueText.csv')\n","df2=pd.read_csv('/content/drive/My Drive/1000ml/Project 7 - Chatbot/Data/dialogueText_196.csv')\n","df3=pd.read_csv('/content/drive/My Drive/1000ml/Project 7 - Chatbot/Data/dialogueText_301.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2xsuy3F_1Mo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1592342371014,"user_tz":240,"elapsed":604,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"65596a7d-20f3-494b-8e44-da38d7178ae0"},"source":["df1.head(2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>folder</th>\n","      <th>dialogueID</th>\n","      <th>date</th>\n","      <th>from</th>\n","      <th>to</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>126125.tsv</td>\n","      <td>2008-04-23T14:55:00.000Z</td>\n","      <td>bad_image</td>\n","      <td>NaN</td>\n","      <td>Hello folks, please help me a bit with the fol...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>126125.tsv</td>\n","      <td>2008-04-23T14:56:00.000Z</td>\n","      <td>bad_image</td>\n","      <td>NaN</td>\n","      <td>Did I choose a bad channel? I ask because you ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   folder  dialogueID  ...   to                                               text\n","0       3  126125.tsv  ...  NaN  Hello folks, please help me a bit with the fol...\n","1       3  126125.tsv  ...  NaN  Did I choose a bad channel? I ask because you ...\n","\n","[2 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"h7mLHLgaHNzm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1592344424430,"user_tz":240,"elapsed":602,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"b3609708-ef31-4625-94ed-4dc3b78bd38f"},"source":["df1['text'].astype(str)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0          Hello folks, please help me a bit with the fol...\n","1          Did I choose a bad channel? I ask because you ...\n","2          the second sentence is better english   and we...\n","3                                               Sock Puppe?t\n","4                                                       WTF?\n","                                 ...                        \n","1038319                                           anyone on?\n","1038320                                                  yes\n","1038321    can I get a pastebin of someones menu.lst with...\n","1038322                         http://pastebin.com/fe921690\n","1038323                                               thanks\n","Name: text, Length: 1038324, dtype: object"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"4KWpol6h_mdt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1592344477743,"user_tz":240,"elapsed":5074,"user":{"displayName":"Karl Davidson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9w6TlOQK5_j4sBkaAza6zpbaYA3qM6SUTrnVXYA=s64","userId":"10038756410563164123"}},"outputId":"d090850f-d56f-4822-e0f7-587dffd0f423"},"source":["# With these, I'll want to extract the text from each individual conversation. I should be able to do this with a simple group by statement\n","df1['text'] = df1['text'].astype(str)\n","df1.groupby('dialogueID')['text'].agg(lambda x: ''.join(x))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dialogueID\n","1.tsv        Also guys, I'm trying to get into my FIrefox p...\n","10.tsv       ugh ;(  http://planet.ubuntulinux.org seems to...\n","100.tsv      ohh to latehttp://www.ubuntulinux.org/ubuntu/l...\n","1000.tsv     see bug 67085sorry, typo, ignore that... try t...\n","10000.tsv    How do I get out of this annoying unity? I can...\n","                                   ...                        \n","99995.tsv    What's locale got to do with 24 hour format?24...\n","99996.tsv    hi all.. i am using rythmbox,  is there aw ay ...\n","99997.tsv    hi i want to know how to i use the Huawei E220...\n","99998.tsv    umm !res is way out of date or something? dpkg...\n","99999.tsv    Does anyone know a good linux distribution ?de...\n","Name: text, Length: 346108, dtype: object"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"CgFN3PnqAAfN","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}